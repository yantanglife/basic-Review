
> 目录来自 [这里](https://www.nowcoder.com/discuss/435836?channel=666&source_id=home_feed) ，复习的同时把这些知识点整理出来     

> 内容大部分来自 [huihut/interview](https://github.com/huihut/interview)

> 使用 [typora](https://www.typora.io/) ( 自定义 `css` ) 保存为 PDF

<a id="content"></a>

# 目录
- [进程线程](#1)
    - [进程、线程的基本概念](#1-1)
        - [什么是进程、线程，彼此有什么区别](#1-1-1)
        - [多进程、多线程的优缺点](#1-1-2)
        - [什么时候用进程、线程](#1-1-3)
        - [多进程、多线程同步](#1-1-4)
    - [并发、同步、异步、互斥、阻塞、非阻塞](#1-2) 
        - [线程同步和互斥](#1-2-1)
        - [线程同步和阻塞](#1-2-2)
        - [并发、同步、异步、互斥、阻塞、非阻塞的理解](#1-2-3)
    - [孤儿进程、僵尸进程、守护进程](#1-3)
        - [基本概念](#1-3-1)
        - [如何创建守护进程](#1-3-2)
        - [正确处理僵尸进程的方法](#1-3-3)
        - [补充](#1-3-4)
- [C/C++](#2) 
    - [C/C++ 区别、概念相关](#2-1) 
        - [new 和 malloc 的区别](#2-1-1)
        - [malloc 的底层实现](#2-1-2)
        - [在 1G 内存的计算机中能否 malloc(1.2G)?](#2-1-3)
        - [指针与引用](#2-1-4)
        - [C语言检索内存情况、内存分配的方式](#2-1-5)
        - [extern"C" 的作用](#2-1-6)
        - [头文件声明时加extern 定义时不要加 因为extern可以多次声明，但只有一个定义](#2-1-7)
        - [函数参数压栈顺序，即关于 __stdcall 和 __cdecl 调用方式的理解](#2-1-8)
        - [重写 memcpy() 函数需要注意哪些问题](#2-1-9)
        - [数组到底存放在哪里](#2-1-10)
        - [struct 和 class 的区别](#2-1-11)
        - [char 和 int 之间的转换](#2-1-12)
        - [static 的用法 (定义和用途)](#2-1-13)
        - [const 用法 (定义和用途)](#2-1-14)
        - [const 常量和 #define 的区别](#2-1-15)
        - [volatile 作用和用法](#2-1-16)
        - [有常量指针 指针常量 常量引用 没有 引用常量](#2-1-17)
        - [没有指向引用的指针，因为引用是没有地址的，但是有指针的引用](#2-1-18)
        - [C/C++ 中变量的作用域](#2-1-19)
        - [C++ 类型转换机制](#2-1-20)
        - [四种智能指针](#2-1-21)
    - [继承、多态相关](#2-2)
        - [继承和虚继承](#2-2-1)
        - [多态的类，内存布局是怎么样的](#2-2-2)
        - [被隐藏的基类函数如何调用或者子类调用父类的同名函数和父类成员变量](#2-2-3)
        - [多态实现的三个条件](#2-2-4)
        - [拷贝构造函数与深浅拷贝](#2-2-5)
        - [什么情况下会调用拷贝构造函数 (三种情况)](#2-2-6)
        - [析构函数可以抛出异常吗?](#2-2-7)
        - [析构函数一般写成虚函数的原因](#2-2-8)
        - [构造函数为什么一般不定义为虚函数](#2-2-9)
        - [纯虚函数](#2-2-10)
        - [静态绑定和动态绑定](#2-2-11)
        - [C++ 的构造函数](#2-2-12)
        - [重写 (覆盖)、重载、隐藏的区别](#2-2-13)
        - [成员初始化列表](#2-2-14)
        - [如何避免编译器进行的隐式类型转换 (explicit)](#2-2-15)
        - [定义无法被继承的类](#2-2-16)
        - [override 和 final 关键字](#2-2-17)
- [网络编程](#3)
    - [TCP UDP](#3-1)
        - [TCP、UDP 区别](#3-1-1)
        - [TCP、UDP 优缺点](#3-1-2)
        - [TCP、UDP 适用场景](#3-1-3)
        - [TCP 为什么是可靠连接](#3-1-4)
        - [典型网络模型，简单说说有哪些](#3-1-5)
        - [Http1.1 和 Http1.0 的区别](#3-1-6)
        - [URI (统一资源标识符) 和 URL (统一资源定位符) 之间的区别](#3-1-7)
    - [三次握手、四次挥手 ](#3-2)
        - [什么是三次握手](#3-2-1)
        - [为什么三次握手中客户端还要发送一次确认呢?可以二次握手吗?](#3-2-2)
        - [为什么服务端易受到 SYN 攻击?](#3-2-3)
        - [什么是四次挥手](#3-2-4)
        - [为什么客户端最后还要等待 2MSL?](#3-2-5)
        - [为什么建立连接是三次握手，关闭连接却是四次挥手呢?](#3-2-6)
    - [应用层](#3-3)
        - [DNS](#3-3-1)
        - [HTTP](#3-3-2)
        - [HTTPS](#3-3-3) 
- [常见算法](#4) 
    - [排序算法](#4-1) 
        - [各种排序算法的时间空间复杂度、稳定性](#4-1-1)
        - [各种排序算法什么时候有最好情况、最坏情况](#4-1-2)
    - [STL](#4-2)
        - [vector list异同](#4-2-1)
        - [vector 内存是怎么增长的](#4-2-1)
        - [vector 和 deque 的比较](#4-2-1)
        - [sort](#4-2-1)
        - [STL底层数据结构实现](#4-2-1)
        - [利用迭代器删除元素会发生什么？](#4-2-1)
        - [map是如何实现的，查找效率是多少](#4-2-1)
        - [几种模板插入的时间复杂度](#4-2-1)
- [Linux操作系统](#5) 
    - [Linux 内核相关](#5-1)
    - [其他操作系统](#5-2)
        - [大小端](#5-2-1)
        - [一个程序从开始运行到结束的完整过程 (四个过程)](#5-2-2)
- [其他](#6)
    - [编程语言](#6-1)
        - [垃圾回收机制](#6-1-1) 
    - [Git](#6-2)
        - [rebase](#6-2-1)
    - [Python](#6-3)
        - [is 与 ==](#6-3-1)
        - [迭代器、生成器](#6-3-2)
        - [装饰器](#6-3-3)
        - [GIL](#6-3-4)
        - [协程](#6-3-5)
    - [MySql](#6-4)
        - [基本概念](#6-4-1)
        - [Innodb 中事务隔离级别和锁的关系](#6-4-2)
        - [索引](#6-4-3)
        - [B 树和 B+ 树](#6-4-4)
    - [Redis](#6-5)
        - [数据类型](#6-5-1)
        - [持久化机制](#6-5-2)
        - [缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级](#6-5-3)
        - [Memcache 与 Redis 区别](#6-5-4)
        - [单线程的 Redis](#6-5-5)
        - [过期策略和内存淘汰机制](#6-5-6)
        - [内部数据结构](#6-5-7)
- [附录](#appendix)
    - [排序算法](#sort-algorithm)	
<div STYLE="page-break-after: always;"></div>

<a id="1"></a>

# 进程线程

<a id="1-1"></a>

## 1.1 进程、线程的基本概念 `⭐⭐⭐⭐⭐` 

<a id="1-1-1"></a>

### 1.1.1 什么是进程、线程，彼此有什么区别 `⭐⭐⭐⭐⭐`

进程是系统资源分配的独立实体，每个进程都拥有独立的地址空间。一个进程无法访问另一个进程的变量和数据结构，如果想让一个进程访问另一个进程的资源，需要使用进程间通信，比如管道，文件，套接字等。

 一个进程可以拥有多个线程，每个线程使用其所属进程的栈空间。线程与进程的一个主要区别是，同一进程内的多个线程会共享部分状态，多个线程可以读写同一块内存（一个进程无法直接访问另一进程的内存）。同时，每个线程还拥有自己的寄存器和栈，其他线程可以读写这些栈内存。

线程是进程的一个实体，是进程的一条执行路径。

线程是进程的一个特定执行路径。当一个线程修改了进程的资源，它的兄弟线程可以立即看到这种变化。
<div align="right"><a href="#content">⏫</a></div>
<a id="1-1-2"></a>

### 1.1.2 多进程、多线程的优缺点 `⭐⭐⭐⭐` 

**对比**
|<center>对比维度</center>|<center>多进程</center>|<center>多线程</center>|<center>总结</center>|
|:--|:--|:--|:--|
|数据共享、同步|数据共享复杂，需要用IPC；<br>数据是分开的，同步简单|因为共享进程数据，数据共享简单；<br>但也因为这个原因导致同步复杂|各有优势|
|内存、CPU|占用内存多，切换复杂，CPU利用率低|占用内存少，切换简单，CPU利用率高|线程占优|
|创建销毁、切换|创建销毁、切换复杂，速度慢|创建销毁、切换简单，速度很快|线程占优|
|编程、调试|编程、调试简单|编程、调试复杂||
|可靠性|进程间不会互相影响|一个线程挂掉将导致整个进程挂掉||
|分布式|适用于多核、多机分布式；<br>如果一台机器不够，扩展到多台机器比较简单|适用于多核分布式||

**优劣**
|<center>优劣</center>|<center>多进程</center>|<center>多线程</center>|
|:--|:--|:--|
|优点|编程、调试简单，可靠性较高|创建、销毁、切换速度快，内存、资源占用小|
|缺点|创建、销毁、切换速度慢，内存、资源占用大|编程、调试复杂，可靠性较差|

<div align="right"><a href="#content">⏫</a></div>
<a id="1-1-3"></a>

### 1.1.3 什么时候用进程，什么时候用线程 `⭐⭐⭐` 
- 需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程的代价是很大的
- 线程的切换速度快，所以在需要大量计算、切换频繁时使用线程，还有耗时的操作时用使用线程可提高应用程序的响应
- 因为对 CPU 系统的效率使用上线程更占优势，所以可能要发展到多机分布的用进程，多核分布用线程
- 并行操作时用线程，如 C/S 架构的服务器端并发线程响应用户的请求
- 需要更稳定安全时，适合选择进程；需要速度时，选择线程更好

<div align="right"><a href="#content">⏫</a></div>
<a id="1-1-4"></a>

### 1.1.4 多进程、多线程同步 (通讯) 的方法 `⭐⭐⭐⭐⭐` 
#### 进程之间的通信方式以及优缺点
- **管道** (PIPE)
    - **有名管道**：一种半双工的通信方式，它允许无亲缘关系进程间的通信
        - 优点：可以实现任意关系的进程间的通信
        - 缺点：
            - 长期存于系统中，使用不当容易出错
            - 缓冲区有限
    - **无名管道**：一种半双工的通信方式，只能在具有亲缘关系的进程间使用 (父子进程)
        - 优点：简单方便
        - 缺点：
            - 局限于单向通信
            - 只能创建在它的进程以及其有亲缘关系的进程之间
            - 缓冲区有限
- **信号量** (Semaphore) ：一个计数器，可以用来控制多个线程对共享资源的访问
    - 优点：可以同步进程
    - 缺点：信号量有限
- **信号** (Signal) ：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
- **消息队列** (Message Queue) ：是消息的链表，存放在内核中并由消息队列标识符标识
    - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
    - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合
- **共享内存** (Shared Memory) ：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
    - 优点：无须复制，快捷，信息量大
    - 缺点：
- 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
- 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信

- **套接字** (Socket) ：可用于不同计算机间的进程通信
    - 优点：
        - 传输数据为字节级，传输数据可自定义，数据量小效率高
        - 传输数据时间短，性能高
        - 适合于客户端和服务器端之间信息实时交互
        - 可以加密,数据安全性强
    - 缺点：需对传输的数据进行解析，转化成应用级的数据

#### 线程之间的通信方式
- 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
    - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
    - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
    - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
    - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制 (Semaphore)
    - 无名线程信号量
    - 命名线程信号量
- 信号机制 (Signal) ：类似进程间的信号处理
- 屏障 (barrier)：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

线程间通信的目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制

<div align="right"><a href="#content">⏫</a></div>
<a id="1-1-5"></a>

### 1.1.5 进程的空间模型⭐⭐⭐⭐ 
Linux 下使用虚拟内存空间给每一个进程，32 位操作系统下，每个进程都有独立的 4G 虚拟内存空间。

其中包括：

1、内核区：用户代码不可见的区域，页表就存放在这个区域中。

2、用户区：
- a、代码段：只可读，不可写，程序代码段。
- b、数据段：保存全局变量，静态变量的区域。
- c、堆区：就是动态内存，通过 `malloc`，`new` 申请内存，有一个堆指针，可以通过 `brk` 系统调用调整堆指针。
- d、文件映射区域：通过 `mmap` 系统调用，如动态库，共享内存等映射物理空间的内存区域。可以单独释放，不会产生内存碎片。
- e、栈区：用于维护函数调用的上下文空间，用 `ulimit -s` 查看。一般默认为 8M

> [参考](https://blog.csdn.net/gfgdsg/article/details/42709943)

<div align="right"><a href="#content">⏫</a></div>
<a id="1-1-6"></a>

### 1.1.6 进程线程的状态转换图 什么时候阻塞，什么时候就绪⭐⭐⭐ 

<a id="1-1-7"></a>

### 1.1.7 父进程、子进程的关系以及区别⭐⭐⭐⭐

<a id="1-1-8"></a>

### 1.1.8 什么是进程上下文、中断上下文⭐⭐ 

<a id="1-1-9"></a>

### 1.1.9 一个进程可以创建多少线程，和什么有关⭐⭐ 

<a id="1-2"></a>

## 1.2 并发，同步，异步，互斥，阻塞，非阻塞的理解 

<a id="1-2-1"></a>

### 1.2.1 什么是线程同步和互斥 `⭐⭐⭐⭐⭐` 

- 互斥是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的
- 同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问
- 同步其实已经实现了互斥，所以同步是一种更为复杂的互斥
- 互斥是一种特殊的同步

所谓互斥，就是不同线程通过竞争进入临界区（共享的数据和硬件资源），为了防止访问冲突，在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写

同步关系则是多个线程彼此合作，通过一定的逻辑关系来共同完成一个任务。一般来说，同步关系中往往包含互斥，同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用

总的来说，两者的区别就是：
- 互斥是通过竞争对资源的独占使用，彼此之间不需要知道对方的存在，执行顺序是一个乱序
- 同步是协调多个相互关联线程合作完成任务，彼此之间知道对方存在，执行顺序往往是有序的

<div align="right"><a href="#content">⏫</a></div>
<a id="1-2-2"></a>

### 1.2.2 线程同步与阻塞的关系?同步一定阻塞吗?阻塞一定同步吗? `⭐⭐⭐⭐` 

**同步是个过程，阻塞是线程的一种状态**。
多个线程操作共享变量时可能会出现竞争。这时需要同步来防止两个以上的线程同时进入临界区，在这个过程中，后进入临界区的线程将阻塞，等待先进入的线程走出临界区

**线程同步不一定发生阻塞**。线程同步的时候，需要协调推进速度，互相等待和互相唤醒会发生阻塞

> 是不是可以理解为，线程同步时会产生阻塞，即“线程同步不一定发生阻塞、阻塞一定同步”？

<div align="right"><a href="#content">⏫</a></div>
<a id="1-2-3"></a>

### 1.2.3 并发，同步，异步，互斥，阻塞，非阻塞的理解 `⭐⭐⭐⭐⭐`

**同步**

- 同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回
- 要想实现同步操作，必须要获得线程的对象锁。获得它可以保证在同一时刻只有一个线能够进入临界区，并且在这个锁被释放之前，其他的线程都不能再进入这个临界区。如果其他线程想要获得这个对象的锁，只能进入等待队列等待。只有当拥有该对象锁的线程退出临界区时，锁才会被释放，等待队列中优先级最高的线程才能获得该锁。
- 实现同步的方式有两种：同步方法、同步代码块

**异步**
- 当一个异步过程调用发出后，调用者不会立刻得到结果。实际处理这个调用的部件是在调用发出后，**通过状态、通知来通知调用者，或通过回调函数处理这个调用**  
- 由于每个线程都包含了运行时自身所需要的数据或方法，因此，在进行输入输出时，不必关心其他线程的状态或行为，也不必等到输入输出处理完毕才返回。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，异步能够提高程序的效率

**阻塞**
- 阻塞调用是指调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回

**非阻塞**
- 指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回

**并发**
- 并发和并行都能表示两个或多个任务一起执行，但是并发偏重于任务交替执行，多个任务之间很可能是串行的，而并行是真正意义上的"同时执行"

<div align="right"><a href="#content">⏫</a></div>
<a id="1-3"></a>

## 1.3 孤儿进程、僵尸进程、守护进程的概念 
> [参考](https://blog.csdn.net/wumenglu1018/article/details/53406537)

<a id="1-3-1"></a>

### 1.3.1 基本概念 `⭐⭐⭐⭐⭐` 
在 *unix*/*linux* 中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。        
子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。当一个进程完成它的工作终止之后，它的父进程需要调用 `wait()` 或者`waitpid()` 系统调用取得子进程的终止状态。        

- 如果一个子进程结束了，但是他的父进程没有等待他, 那么这个子进程将变成一个僵尸进程
- 但是如果该进程的父进程已经先结束了，那么该进程就不会变成僵尸进程，因为每个进程结束的时候，系统都会扫描当前系统中所运行的所有进程，看有没有哪个进程是刚刚结束的这个进程的子进程，如果是的话，就由 `Init`（进程号为1）来接管他，成为他的父进程，此时称这个进程为孤儿进程，其状态收集工作由 `Init` 进程负责

**孤儿进程**

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被 `Init` 进程所收养，并由 `Init` 进程对它们完成状态收集工作

**僵尸进程**

一个进程使用 `fork` 创建子进程，如果子进程退出，而父进程并没有调用 `wait` 或 `waitpid` 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程

**守护进程**

守护进程就是在后台运行，不与任何终端关联的进程，通常情况下守护进程在系统启动时就在运行，它们以 *root* 用户或者其他特殊用户 ( *apache* 和 *postfix* ) 运行，并能处理一些系统级的任务。习惯上守护进程的名字通常以 ***d*** 结尾 (*sshd*)，但这不是必须的。

<div align="right"><a href="#content">⏫</a></div>
<a id="1-3-2"></a>

### 1.3.2 如何创建守护进程：⭐⭐ 

<a id="1-3-3"></a>

### 1.3.3 正确处理僵尸进程的方法 `⭐⭐⭐⭐`
#### 通过信号机制
子进程退出时向父进程发送 `SIGCHILD` 信号，父进程处理 `SIGCHILD` 信号。在信号处理函数中调用 `wait` 进行处理僵尸进程。
```c
#include<stdio.h>
#include<unistd.h>
#include<stdlib.h>
#include<signal.h>

static voidsig_child(int signo);

int main() {
    ...
    // 创建捕捉子进程退出信号
    signal(SIGCHILD, sig_child);
    ...
}

static void sig_child(int signo){
    pid_t pid;
    int   stat;
    // 处理僵尸进程
    while ((pid = waitpid(-1, &stat, WNOHANG)) > 0)
        printf("child %dterminated.\n", pid);
}
```

#### 两次 `fork`（ `kill` 父进程）
原理是将子进程成为孤儿进程，从而其的父进程变为 `Init` 进程，通过 `Init` 进程可以处理僵尸进程
```c
#include<stdio.h>
#include<stdlib.h>
#include<unistd.h>
#include<errno.h>

int main() {
    pid_t pid;
    // 创建第一个子进程
    pid = fork();
    if (pid < 0) {
        perror("fork error:");
        exit(1);
    }

    // 第一个子进程
    else if (pid == 0) {
        printf("I am the first childprocess.pid:%d\tppid:%d\n",getpid(),getppid());

        // 子进程再创建子进程
        pid = fork();
        if (pid < 0) {
            perror("fork error:");
            exit(1);
        }

        // 第一个子进程退出
        else if (pid > 0) {
            printf("first procee isexited.\n");
            exit(0);
        }

        // 第二个子进程
        // 睡眠 3s 保证第一个子进程退出，这样第二个子进程的父亲就是init进程里
        sleep(3);
        printf("I am the second childprocess.pid: %d\tppid:%d\n",getpid(),getppid());
        exit(0);
    }

    // 父进程处理第一个子进程退出
    if (waitpid(pid, NULL, 0) != pid) {
        perror("waitepid error:");
        exit(1);
    }

    exit(0);
    return 0;
}
```

<div align="right"><a href="#content">⏫</a></div>
<a id="1-3-4"></a>

### 1.3.4 补充
#### 孤儿进程有危害吗？

孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了 `Init` 进程身上。      
每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为 `Init`，而 `init` 进程会循环地 `wait()` 它的已经退出的子进程。因此孤儿进程并不会有什么危害

#### 僵尸进程有危害吗？
例如有个进程，它定期的产生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若**用 `ps` 命令查看**的话，就会看到很多状态为 `Z` 的进程。 

严格地来说，僵尸进程并不是问题的根源，罪魁祸首是产生出大量僵尸进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵尸进程时，答案就是把产生大量僵尸进程的那个元凶枪毙掉 (也就是通过 `kill` 发送 `SIGTERM` 或者 `SIGKILL` 信号啦)

枪毙了元凶进程（父进程）之后，它产生的僵尸进程就变成了孤儿进程，这些孤儿进程会被 `Init` 进程接管，`Init` 进程会 `wait()` 这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程就能瞑目而去了      
这就是守护进程的作用，如果发生大量的僵尸进程，守护进程就会查找其父进程，然后无情的 `kill` 掉！

#### 为什么要尽量避免僵尸进程？
僵尸进程不是活着的进程，可以说就是一个数据结构，它是已经完成的任务的进程，但是不是它完成任务后就会烟消云散的，他会留下一点东西，这个东西就是他的进程 `Id`，他的结束状态等.       

为什么会留下这个东西呢？        

因为这个是用来向他的父进程报告自己的完成状况的，父进程创建一个进程是用来完成任务，父进程需要知道子进程的完成情况，所以出现这样的机制，对于僵尸进程只有父进程自己可以清理掉，调用 `wait` 等命令就可以了。

但是父进程不清理怎么办，那就说明存在僵尸进程，浪费了进程 `Id`，进程 `id` 是一种有限资源，用一个少一个，所以如果存在大量的僵尸进程，解决方法可以是 `kill` 父进程，把子进程交由 `Init` 进程处理。

系统中的进程数量是有限的，虽然僵尸进程占用的资源和内存都比较少，但是它却占领着进程 `ID`，可能会导致系统无法再创建新的进程，因此及时清除僵尸进程很重要！

<div align="right"><a href="#content">⏫</a></div>
<div STYLE="page-break-after: always;"></div>

<a id="2"></a>

# C/C++

<a id="2-1"></a>

## 2.1 C 和 C++ 区别、概念相关

<a id="2-1-1"></a>

### 2.1.1 `new` 和 `malloc` 的区别 `⭐⭐⭐⭐⭐` 
> [参考](https://blog.csdn.net/nie19940803/article/details/76358673)

#### 属性
`new`/`delete` 是 C++ 关键字，需要编译器支持。`malloc`/`free` 是库函数，需要头文件支持

#### 参数
使用 `new` 操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而 `malloc` 则需要显式地指出所需内存的尺寸
#### 返回类型
`new` 操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故 `new` 是符合类型安全性的操作符。而 `malloc` 内存分配成功则是返回 `void *` ，需要通过强制类型转换将 `void *` 指针转换成我们需要的类型

#### 分配失败
`new` 内存分配失败时，会抛出 `bad_alloc` 异常。`malloc` 分配内存失败时返回 `NULL`

#### 自定义类型
`new` 会先调用 `operator new` 函数，申请足够的内存（通常底层使用 `malloc` 实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。`delete` 先调用析构函数，然后调用 `operator delete` 函数释放内存（通常底层使用 `free` 实现）

`malloc`/`free` 是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作

#### 重载
C++ 允许重载 `new`/`delete` 操作符，特别的，布局 `new` 的就不需要为对象分配内存，而是指定了一个地址作为内存起始区域，`new` 在这段内存上为对象调用构造函数完成初始化工作，并返回此地址。而 `malloc` 不允许重载
#### 内存区域
`new` 操作符从自由存储区（`free store`）上为对象动态分配内存空间，而 `malloc` 函数从堆上动态分配内存。自由存储区是 C++ 基于 `new` 操作符的一个抽象概念，凡是通过 `new` 操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C 语言使用 `malloc` 从堆上分配内存，使用 `free` 释放已分配的对应内存。自由存储区不等于堆，如上所述，布局 `new` 就可以不位于堆中

<div align="right"><a href="#content">⏫</a></div>
<a id="2-1-2"></a>

### 2.1.2 `malloc` 的底层实现 `⭐⭐⭐⭐` 
> [malloc 底层实现及原理](https://www.cnblogs.com/zpcoding/p/10808969.html)

- 当开辟的空间小于 128K 时，调用 `brk()` 函数，`malloc` 的底层实现是系统调用函数 `brk()`，其主要移动指针 `_enddata` (此时的 `_enddata` 指的是 Linux 地址空间中堆段的末尾地址，不是数据段的末尾地址)
- 当开辟的空间大于 128K 时，`mmap()` 系统调用函数来在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟。

<a id="2-1-3"></a>

### 2.1.3 在 1G 内存的计算机中能否 `malloc(1.2G)`?为什么? `⭐⭐`

`malloc` 能够申请的空间大小与物理内存的大小没有直接关系，仅与程序的虚拟地址空间相关

程序运行时，堆空间只是程序向操作系统申请划出来的一大块虚拟地址空间。应用程序通过 `malloc` 申请空间，得到的是在虚拟地址空间中的地址，之后程序运行所提供的物理内存是由操作系统完成的

Windows 下 32 位程序如果单纯看地址空间能有 4G 左右的内存可用，不过实际上系统会把其中 2G 的地址留给内核使用，所以此时程序最大能用2G的内存。除去其他开销，能用 `malloc` 申请到的内存只有 1.9G 左右

<div align="right"><a href="#content">⏫</a></div>
<a id="2-1-4"></a>

### 2.1.4 指针与引用的相同和区别；如何相互转换？⭐⭐⭐⭐⭐ 

<a id="2-1-5"></a>

### 2.1.5 C语言检索内存情况 内存分配的方式⭐⭐⭐ 

<a id="2-1-6"></a>

### 2.1.6 `extern"C"` 的作用 `⭐⭐⭐` 
`extern "C"` 的作用是让 C++ 编译器将 `extern "C"` 声明的代码当作 C 语言代码处理，可以避免 C++ 因符号修饰导致代码不能和 C 语言库中的符号进行链接的问题

<a id="2-1-7"></a>

### 2.1.7 头文件声明时加 `extern` 定义时不要加 因为 `extern` 可以多次声明，但只有一个定义⭐⭐⭐⭐ 

<a id="2-1-8"></a>

### 2.1.8 函数参数压栈顺序，即关于 __stdcall 和 __cdecl 调用方式的理解⭐⭐⭐ 

<a id="2-1-9"></a>

### 2.1.9 重写 `memcpy()` 函数需要注意哪些问题⭐⭐ 

<a id="2-1-10"></a>

### 2.1.10 数组到底存放在哪里⭐⭐⭐ 

<a id="2-1-11"></a>

### 2.1.11 `struct` 和 `class` 的区别 `⭐⭐⭐⭐⭐` 
`struct` 更适合看成是一个数据结构的实现体，`class` 更适合看成是一个对象的实现体

在 C++ 中，`class` 和 `struct` 做类型定义是只有两点区别：
- 成员的默认访问权限。`class` 的成员默认是 `private` 权限，`struct` 默认是 `public` 权限；默认继承权限不同，`class` 继承默认是 `private` 继承，而 `struct` 默认是 `public` 继承
- `class` 还可用于定义模板参数，像 `typename` ，但是关键字 `struct` 不能同于定义模板参数

C++ 保留 `struct` 关键字，原因
- 保证与 C 语言的向下兼容性，C++ 必须提供一个 `struct`
- C++ 中的 `struct` 定义必须百分百地保证与 C 语言中的 `struct` 的向下兼容性，把 C++ 中的最基本的对象单元规定为 `class` 而不是 `struct`，就是为了避免各种兼容性要求的限制
- 对 `struct` 定义的扩展使 C 语言的代码能够更容易的被移植到 C++ 中

<div align="right"><a href="#content">⏫</a></div>
<a id="2-1-12"></a>

### 2.1.12 `char` 和 `int` 之间的转换 `⭐⭐⭐` 
```cpp
// 通过 ascii码
char a = '0';
int ia = (int)a;
ia = ia - 48
// 直接转
int ib = a - '0';
```

<a id="2-1-13"></a>

### 2.1.13 `static` 的用法 (定义和用途) `⭐⭐⭐⭐⭐`
1. 修饰**普通变量**，修改变量的存储区域和生命周期，使变量存储在静态区，在 `main` 函数运行前就分配了空间，如果有初始值就用初始值初始化它，如果没有初始值系统用默认值初始化它
2. 修饰**普通函数**，表明函数的作用范围，仅在定义该函数的文件内才能使用。在多人开发项目时，为了防止与他人命名空间里的函数重名，可以将函数定义为 `static`
3. 修饰**成员变量**，修饰成员变量使所有的对象只保存一个该变量，而且不需要生成对象就可以访问该成员
4. 修饰**成员函数**，修饰成员函数使得不需要生成对象就可以访问该函数，但是在 `static` 函数内不能访问非静态成员

<a id="2-1-14"></a>

### 2.1.14 `const` 的用法 (定义和用途) `⭐⭐⭐⭐⭐`
1. 修饰**变量**，说明该变量不可以被改变；
2. 修饰**指针**，分为指向常量的指针 (`pointer to const`) 和自身是常量的指针 (常量指针，`const pointer`)
3. 修饰**引用**，指向常量的引用 (`reference to const`)，用于形参类型，即避免了拷贝，又避免了函数对值的修改
4. 修饰**成员函数**，说明该成员函数内不能修改成员变量

<div align="right"><a href="#content">⏫</a></div>
<a id="2-1-15"></a>

### 2.1.15 `const` 常量和 `#define` 的区别 (编译阶段、安全性、内存占用等)  `⭐⭐⭐⭐` 
> [const（常量）和#define（宏定义）区别](https://www.cnblogs.com/xumaomao/articles/11049541.html)

宏定义在编译时把所有用到宏定义值的地方用宏定义常量替换。`const` 常量可以看作是一个只读变量，需要指定类型，需要分配内存，有自己的作用域

#### 编译器处理不同
宏定义是一个“编译时”概念，在预处理阶段展开（在编译时把所有用到宏定义值的地方用宏定义常量替换），不能对宏定义进行调试，生命周期结束于编译时期；

`const` 常量是一个“运行时”概念，在程序运行使用，类似于一个只读行数据

#### 存储方式不同
宏定义是直接替换，不会分配内存，存储于程序的代码段中；

`const` 常量需要进行内存分配

#### 类型和安全检查不同
宏定义是字符替换，没有数据类型的区别，同时这种替换没有类型安全检查，可能产生边际效应等错误；

`const` 常量是常量的声明，有类型区别，需要在编译阶段进行类型检查

#### 定义域不同
```cpp
void f1 () {
    #define N 12
    const int n 12;
}
void f2 () {
    cout << N <<endl; // 正确，N已经定义过，不受定义域限制
    cout << n <<endl; // 错误，n定义域只在f1函数中
}
```
#### 是否可以做函数参数
宏定义不能作为参数传递给函数

`const` 常量可以在函数的参数列表中出现

#### 定义后能否取消
宏定义可以通过 `#undef` 来使之前的宏定义失效

`const` 常量定义后将在定义域内永久有效

```cpp
void f1() {
  #define N 12
  const int n = 12;
  #undef N  // 取消宏定义后，即使在 f1函数中，N也无效了
  #define N 21 // 取消后可以重新定义
}
```

<div align="right"><a href="#content">⏫</a></div>
<a id="2-1-16"></a>

### 2.1.16 `volatile` 作用和用法 `⭐⭐⭐⭐⭐`
```cpp
volatile int a = 1;
```
- `volatile` 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素 (操作系统、硬件、其它线程等) 更改。所以使用 `volatile` 告诉编译器不应对这样的对象进行优化。
- `volatile` 关键字声明的变量，每次访问时都必须从内存中取出值 (没有被 `volatile` 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值)
- `const` 可以是 `volatile` (如只读的状态寄存器)
- 指针可以是 `volatile`

<a id="2-1-17"></a>

### 2.1.17 有常量指针 指针常量 常量引用 没有 引用常量⭐⭐⭐ 

<a id="2-1-18"></a>

### 2.1.18 没有指向引用的指针，因为引用是没有地址的，但是有指针的引用⭐⭐⭐ 

<a id="2-1-19"></a>

### 2.1.19 C/C++中变量的作用域 `⭐⭐⭐⭐⭐`
> [c/c++中变量的作用域](https://www.cnblogs.com/eliu/p/8484637.html)

<a id="2-1-20"></a>

### 2.1.20 C++中类型转换机制 `⭐⭐⭐` 

#### `static_cast`
- 用于非多态类型的转换
- 不执行运行时类型检查 (转换安全性不如 `dynamic_cast`)
- 通常用于转换数值数据类型 (如 `float` -> `int`)
- 可以在整个类层次结构中移动指针，子类转化为父类安全（向上转换），父类转化为子类不安全（因为子类可能有不在父类的字段或方法）
#### `dynamic_cast`
- 用于多态类型的转换
- 执行运行时类型检查
- 只适用于指针或引用
- 对不明确的指针的转换将失败 (返回 `nullptr`)，但不引发异常
- 如果转换目标是引用类型并且失败了，则 `dynamic_cast` 运算符将抛出一个 `std::bad_cast` 异常
- 可以在整个类层次结构中移动指针，包括向上转换、向下转换
#### `const_cast`
- 用于删除 `const`、`volatile` 和 `__unaligned` 特性（如将 `const int` 类型转换为 `int` 类型 ）
#### `reinterpret_cast`
- 用于位的简单重新解释
- 滥用 `reinterpret_cast` 运算符可能很容易带来风险。 除非所需转换本身是低级别的，否则应使用其他强制转换运算符之一
- 允许将任何指针转换为任何其他指针类型（如 `char*` 到 `int*` 或 `One_class*` 到 `Unrelated_class*` 之类的转换，但其本身并不安全）
- 也允许将任何整数类型转换为任何指针类型以及反向转换
- `reinterpret_cast` 运算符不能丢掉 `const`、`volatile` 或 `__unaligned` 特性
- `reinterpret_cast` 的一个实际用途是在哈希函数中，即让两个不同的值 (地址值) 几乎不会产生相同的哈希值
```cpp
#include <iostream>
using namespace std;

// Returns a hash code based on an address
unsigned short Hash( void *p ) {
   unsigned int val = reinterpret_cast<unsigned int>( p );
   return ( unsigned short )( val ^ (val >> 16));
}

int main() {
   int a[20];
   for ( int i = 0; i < 20; i++ )
      cout << Hash( a + i ) << endl;
}
```

#### `bad_cast`
因为不存在所谓空引用，所以引用类型的 `dynamic_cast` 转换与指针类型不同，在引用转换失败时，会抛出 `std::bad_cast` 异常，该异常定义在头文件 `typeinfo` 中
```cpp
try {  
    Circle& ref_circle = dynamic_cast<Circle&>(ref_shape);   
}  
catch (bad_cast b) {  
    cout << "Caught: " << b.what();  
} 
```

<div align="right"><a href="#content">⏫</a></div>
<a id="2-1-21"></a>

### 2.1.21 四种智能指针

`STL` 一共提供了四种智能指针：`auto_ptr`、`unique_ptr`、`shared_ptr` 和 `weak_ptr`，`auto_ptr` 是 *C++98* 提供的解决方案，*C++11* 已将其摒弃，并提出了 `unique_ptr` 作为 `auto_ptr` 替代方案

#### `auto_ptr`

在拷贝 / 赋值过程中，直接剥夺原对象对内存的控制权，转交给新对象，然后再将原对象指针置为 `nullptr`。这种做法也叫管理权转移

- 当再次去访问原对象时，程序就会报错
- 不能被复制，所以不能被放入容器中

#### `unique_ptr`

取代 *C++98* `auto_ptr`

##### 安全

`auto_ptr` 有**拷贝语义**，拷贝后原象变得无效，再次访问原对象时会导致程序崩溃；`unique_ptr` 则禁止了拷贝语义，但提供了**移动语义**，即可以使用 `std::move()` 进行控制权限的转移

##### 灵活

如果 `unique_ptr` 是个**临时右值**，编译器允许**拷贝语义**

```cpp
unique_ptr<string> demo(const char* s) {
    unique_ptr<string> temp(new string(s));
    return temp;
}
// 
unique_ptr<string> ps;
ps = demo("unique");
```

`demo()` 返回一个临时 `unique_ptr`，然后 `ps` 接管了临时对象 `unique_ptr` 所管理的资源，而返回时临时的 `unique_ptr` 被销毁，也就是说没有机会使用  `unique_ptr` 来访问无效的数据，换句话来说，这种赋值是不会出现任何问题的，即没有理由禁止这种赋值。实际上，编译器确实允许这种赋值。相对于 `auto_ptr` 任何情况下都允许拷贝语义，这正是 `unique_ptr` 更加灵活聪明的地方

##### 扩展

- unique_ptr可放在**容器**中
- 管理动态数组
- 自定义资源删除操作

#### `shared_ptr`

`shared_ptr` 完善了前两种的不足，既不会直接剥夺原对象对内存的控制权，也允许进行拷贝构造和赋值，这都源自于引入了一个新的标志—**引用计数**

- `shared_ptr` 在其内部，给每个资源都维护了着 1份计数，用来记录该份资源被几个对象共享
- 在对象被销毁时 (也就是析构函数调用)，就说明自己不使用该资源了，对象的引用计数减 1
- 如果引用计数是 0，就说明自己是最后一个使用该资源的对象，必须释放该资源
- 如果不是0，就说明除了自己还有其他对象在使用该份资源，不能释放该资源，否则其他对象就成野指针了

#### `weak_ptr`

`weak_ptr` 是为了配合 `shared_ptr` 而引入的一种智能指针，它更像是 `shared_ptr` 的一个**助手**而不是智能指针，因为它不具有普通指针的行为，**没有重载`operator*`和 `->`**，因此取名为 `weak`，表明其是功能较弱的智能指针。它的最大作用在于协助 `shared_ptr` 工作，可**获得资源的观测权**，像旁观者那样观测资源的使用情况。观察者意味着 `weak_ptr` 只**对shared_ptr 进行引用**，而**不改变其引用计数**，当被观察的 `shared_ptr` 失效后，相应的 `weak_ptr` 也相应失效

#### 智能指针是线程安全的吗？
- 对于 `unique_ptr`，由于只是在当前代码块范围内有效。所以不涉及线程安全的问题
- 对于 `shared_ptr`，多个对象要同时共用一个引用计数变量，所以会存在线程安全的问题，但是标准库实现的时候考虑到了这一点，使用了基于原子操作 (CAS) 的方式来保证 `shared_ptr`能够高效、原子的操作引用计数 (**但是， 对同一个 `shared_ptr` 实例的并发操作需要自己保证安全性**)

#### 小结

- 不要使用 `auto_ptr`，**拷贝构造/赋值**的时候会带来很大的麻烦
- 在不需要拷贝构造/赋值的时候，可以使用 `unique_ptr`
- 有拷贝构造/赋值的情况，推荐使用 `shared_ptr`
- 类内有访问其他 `shared_ptr` 对象时，指针类型设为 `weak_ptr` ，可以不改 `shared_ptr` 对象的引用计数
- 代码中尽量不用 `delete` 关键字，因为内存的管理与释放全权交给对象处理

<div align="right"><a href="#content">⏫</a></div>

<a id="2-2"></a>

## 2.2 继承、多态 `⭐⭐⭐⭐⭐`

<a id="2-2-1"></a>

### 2.2.1 继承和虚继承 `⭐⭐⭐⭐⭐`

虚继承用于解决多继承条件下的菱形继承问题 (浪费存储空间、存在二义性)

底层实现原理与编译器相关，一般通过虚基类指针和虚基类表实现，每个虚继承的子类都有一个虚基类指针 (占用一个指针的存储空间，4字节) 和虚基类表 (不占用类对象的存储空间) (需要强调的是，虚基类依旧会在子类里面存在拷贝，只是仅仅最多存在一份而已，并不是不在子类里面了) ；当虚继承的子类被当做父类继承时，虚基类指针也会被继承。

实际上，`vbptr` 指的是虚基类表指针 (`virtual base table pointer`)，该指针指向了一个虚基类表 (`virtual table`)，虚表中记录了虚基类与本类的偏移地址；通过偏移地址，这样就找到了虚基类成员，而虚继承也不用像普通多继承那样维持着公共基类 (虚基类) 的两份同样的拷贝，节省了存储空间。
```cpp
// A 占 16 字节
class A {
public:
    int a;
    double ad;
};

// 在 32 位环境下, 大小为 24
// 虚基类表指针 - 4，b - 4， A - 16
class B : virtual public A {
public:
    int b;
};

// 与B一样
class C : virtual public A {
public:
    int c;
};

// 在 32 位环境下,大小为 40
// B.vbptr - 4, b - 4
// C.vbptr - 4, c - 4
// d - 4, 对齐 - 4
// A - 16
class D :public B, public C {
public:
    int d;
};

void test() {
    std::cout << sizeof(A) << std::endl;        // 16  
    std::cout << sizeof(B) << std::endl;        // 24
    std::cout << sizeof(C) << std::endl;        // 24
    std::cout << sizeof(D) << std::endl;        // 40
    std::cout << sizeof(void *) << std::endl;   // 4
    // 若不是虚继承
    // sizeof(A) = 16
    // sizeof(B) = 24 
    // A - 16, b - 4, 对齐 - 4
    // sizeof(D) = 56
    // B - 24, C - 24, d = 4, 对齐 - 4
}
```

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-2"></a>

### 2.2.2 多态的类，内存布局是怎么样的 `⭐⭐⭐⭐⭐`

C++ 继承分为两种，普通继承和虚拟继承 ( `virtual` )。     
具体的继承又根据父类中的函数是否 `virtual` 而不同。

#### 单继承
##### 普通继承 + 父类无 `virtual` 函数
- 若子类没有新定义 `virtual` 函数 

此时子类的布局是 :
由 低地址->高地址 为父类的元素 (没有 `vptr` )，子类的元素 (没有 `vptr` ).

- 若子类有新定义 `virtual` 函数 

此时子类的布局是 :
由 低地址->高地址 为父类的元素 (没有 `vptr` )，子类的元素 (包含 `vptr`, 指向 `Vtable` .)

##### 普通继承 + 父类有 `virtual` 函数
不管子类没有新定义 `virtual` 函数 此时子类的布局是 : 由低地址->高地址 为父类的元素 (包含 `vptr` )，子类的元素.       
如果子类有新定义的 `virtual` 函数，那么在父类的 `vptr` (也就是第一个 `vptr` ) 对应的 `Vtable` 中添加一个函数指针.

##### `virtual` 继承
- 若子类没有新定义 `virtual` 函数 此时子类的布局是 :

由 低地址->高地址 子类的元素 (有 `vptr` )，虚基类的元素.      
为什么这里会出现 `vptr`，因为虚基类派生出来的类中，虚类的对象不在固定位置(猜测应该是在内存的尾部)，需要一个中介才能访问虚类的对象.所以虽然没有 `virtual` 函数，子类也需要有一个 `vptr` ，对应的 `Vtable` 中需要有一项指向虚基类.

- 若子类有新定义 `virtual` 函数，此时子类的布局是与没有定义新 `virtual` 函数内存布局一致。但是在 `Vtable` 中会多出新增的虚函数的指针.

#### 多重继承
> 2.2.1

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-3"></a>

### 2.2.3 被隐藏的基类函数如何调用或者子类调用父类的同名函数和父类成员变量 `⭐⭐⭐⭐⭐`

同名成员函数，即不管参数是否相同、返回值是否相同，只要函数名称相同，就是同名成员函数，如果子类和基类定义了这样的函数，子类就会把基类的相应函数隐藏掉

- 当子类中含有和基类同名的成员变量时，再用子类的对象调用该同名成员变量时，将只会调用到子类自身定义的成员变量，而不会调用到基类的同名成员变量，这种现象就叫做隐藏，子类把基类的同名成员变量隐藏了，正确调用方式：`Derived.Base::m_value;`

- 当子类中含有和基类同名的成员函数时，再用子类的对象调用该同名成员函数时，将只会调用到子类自身定义的成员函数，而不会调用到基类定义的同名的成员函数，这也是因为子类把基类的同名成员函数隐藏了；正确调用方法：`Derived.Base::func();`

<a id="2-2-4"></a>

### 2.2.4 多态实现的三个条件、实现的原理 `⭐⭐⭐⭐⭐` 

1. 继承
2. 方法的重写
3. 父类指针指向子类对象

C++ 多态分类及实现：
- 重载多态（Ad-hoc Polymorphism，编译期）：函数重载、运算符重载
- 子类型多态（Subtype Polymorphism，运行期）：虚函数
- 参数多态性（Parametric Polymorphism，编译期）：类模板、函数模板
- 强制多态（Coercion Polymorphism，编译期/运行期）：基本类型转换、自定义类型转换

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-5"></a>

### 2.2.5 拷贝构造函数与深浅拷贝 `⭐⭐⭐`
当出现类的等号赋值时，会调用拷贝函数，在未定义显示拷贝构造函数的情况下，系统会调用默认的拷贝函数——即浅拷贝，它能够完成成员的一一复制

当数据成员中没有指针时，浅拷贝是可行的。但当数据成员中有指针时，如果采用简单的浅拷贝，则两类中的两个指针将指向同一个地址，当对象快结束时，会调用两次析构函数，而导致指针悬挂现象。所以，这时必须采用深拷贝

拷贝构造函数的**作用**就是用来复制对象的，在使用这个对象的实例来初始化这个对象的一个新的实例

**什么情况下必须定义拷贝构造函数？**        
当类的对象用于函数值传递时 (值参数，返回类对象)，拷贝构造函数会被调用。如果对象复制并非简单的值拷贝，那就必须定义拷贝构造函数        
如果定义了拷贝构造函数，那也必须重载赋值操作符

#### 补充
##### 参数传递
- 值传递
    - 对于内置数据类型的传递时，直接赋值拷贝给形参 (注意形参是函数内局部变量)
    - 对于类类型的传递时，需要首先调用该类的拷贝构造函数来初始化形参 (局部对象)
- 引用传递:
    - 无论对内置类型还是类类型，传递引用或指针最终都是传递的地址值！而地址总是指针类型 (属于简单类型)，显然参数传递时，按简单类型的赋值拷贝，而不会有拷贝构造函数的调用 (对于类类型).
##### 为什么拷贝构造函数必须是引用传递，不能是值传递？
为了防止递归引用

具体一些可以这么讲：        
当一个对象需要以值方式传递时，编译器会生成代码调用它的拷贝构造函数以生成一个副本。如果类 A 的拷贝构造函数是以值方式传递一个类 A 对象作为参数的话，当需要调用类A的拷贝构造函数时，需要以值方式传进一个A的对象作为实参；而以值方式传递需要调用类A的拷贝构造函数；结果就是调用类 A 的拷贝构造函数导致又一次调用类 A 的拷贝构造函数，这就是一个无限递归

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-6"></a>

### 2.2.6 什么情况下会调用拷贝构造函数 (三种情况) `⭐⭐⭐`
1. 用类的一个对象去初始化另一个对象的时候
2. 当函数的参数是类的对象时，就是值传递的时候，如果是引用传递则不会调用
3. 当函数的返回值是类的对象或者引用的时候

<a id="2-2-7"></a>

### 2.2.7 析构函数可以抛出异常吗? `⭐⭐⭐` 

C++ 异常处理模型最大的特点和优势就是对 C++ 中的面向对象提供了最强大的无缝支持。那么如果对象在运行期间出现了异常，C++ 异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象 (也即对象超出了它原来的作用域)，并释放对象原来所分配的资源，这就是调用这些对象的析构函数来完成释放资源的任务，所以从这个意义上说，析构函数已经变成了异常处理的一部分

- 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题

- 通常异常发生时，C++ 的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题

**那么当无法保证在析构函数中不发生异常时，该怎么办?**

把异常完全封装在析构函数内部 (`try catch`)，决不让异常抛出函数之外。这是一种非常简单，也非常有效的方法

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-8"></a>

### 2.2.8 析构函数一般写成虚函数的原因 `⭐⭐⭐⭐⭐`

析构函数可以为虚函数，当析构一个指向派生类的基类指针时，最好将基类的析构函数声明为虚函数，否则可能存在内存泄露的问题

如果析构函数不被声明成虚函数，则编译器实施静态绑定，在删除指向派生类的基类指针时，只会调用基类的析构函数而不调用派生类析构函数，这样就会造成派生类对象析构不完全

<a id="2-2-9"></a>

### 2.2.9 构造函数为什么一般不定义为虚函数 `⭐⭐⭐⭐⭐`

- 因为创建一个对象时需要确定对象的类型，而虚函数是在运行时确定其类型的。而在构造一个对象时，由于对象还未创建成功，编译器无法知道对象的实际类型，是类本身还是类的派生类等等

- 虚函数的调用需要虚函数表指针，而该指针存放在对象的内存空间中；若构造函数声明为虚函数，那么由于对象还未创建，还没有内存空间，更没有虚函数表地址用来调用虚函数即构造函数了

在调用构造函数时，虚表指针并没有在对象的内存空间中，必须要构造函数调用完成后才会形成虚表指针

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-10"></a>

### 2.2.10 纯虚函数 `⭐⭐⭐⭐⭐`
纯虚函数是一种特殊的虚函数，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的派生类去做

析构函数可以是纯虚的，但纯虚析构函数必须有定义体，因为析构函数的调用是在子类中隐含的

- 虚函数语法只是表明这个函数是一个纯虚函数，因此这个类变成了抽象类，不能产生对象。我们完全可以为纯虚函数指定函数体。通常的纯虚函数不需要函数体，是因为我们一般不会调用抽象类的这个函数，只会调用派生类的对应函数
```cpp
class Base {
public:
    Base() {}
    // 没有其他合适的函数，可以把析构函数定义为纯虚的
    virtual ~Base() = 0;
};

// Derived 的析构函数里面隐含调用了 Base 的析构函数
// 不能缺少 ~Base()的函数体
Base::~Base() {
    // std::cout << "~Base()" << std::endl;
}

class Derived : public Base {
public:
    Derived() {}
    ~Derived() {
        //std::cout << "~Derived()" << std::endl;
    }
};

void test() {
    Base* pD = new Derived();
    delete pD;
}
```

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-11"></a>

### 2.2.11 静态绑定和动态绑定的介绍 `⭐⭐⭐⭐`

- 静态类型：对象在声明时采用的类型，在编译期既已确定
- 动态类型：通常是指一个指针或引用目前所指对象的类型，是在运行期决定的
- 静态绑定：绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期
- 动态绑定：绑定的是动态类型，所对应的函数或属性依赖于对象的动态类型，发生在运行期

从上面的定义也可以看出，非虚函数一般都是静态绑定，而虚函数都是动态绑定（如此才可实现多态性）

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-12"></a>

### 2.2.12 C++ 的构造函数 `⭐⭐⭐`
构造函数的作用：初始化对象的数据成员

默认构造函数、拷贝构造函数、移动构造函数

委托构造函数、继承构造函数

<a id="2-2-13"></a>

### 2.2.13 重写 (覆盖)、重载、隐藏的区别 `⭐⭐⭐⭐⭐`
`override` 是指派生类中存在重新定义的函数。其函数名，参数列表，返回值类型，所有都必须同基类中被重写的函数一致。只有函数体不同（花括号内），派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有 `virtual` 修饰

`overload` 是指同一可访问区内被声明的几个具有不同参数列表（参数的类型，个数，顺序不同）的同名函数，根据参数列表确定调用哪个函数，重载不关心函数返回类型

**隐藏**是指派生类的函数屏蔽了与其同名的基类函数。注意只要同名函数，不管参数列表是否相同，基类函数都会被隐藏

<a id="2-2-14"></a>

### 2.2.14 成员初始化列表 `⭐⭐⭐⭐` 

在类构造函数中，不在函数体内对变量赋值，而在参数列表后，跟一个冒号和初始化列表

更高效：少了一次调用默认构造函数的过程。
有些场合必须要用初始化列表：

- 常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面
- 引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面
- 没有默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化

<div align="right"><a href="#content">⏫</a></div>
<a id="2-2-15"></a>

### 2.2.15 如何避免编译器进行的隐式类型转换 (explicit) `⭐⭐⭐⭐`
- `explicit` 修饰构造函数时，可以防止隐式转换和复制初始化
- `explicit` 修饰转换函数时，可以防止隐式转换

<a id="2-2-16"></a>

### 2.2.16 定义无法被继承的类

> [1](https://www.cnblogs.com/Rosanna/p/3339823.html)
>
> [2](https://www.cnblogs.com/kingstarspe/archive/2013/06/06/virtualpublic.html)

将它的构造函数和析构函数定义为 `private`，然后定义公有的静态函数来创建和释放类的实例，实现该类不能被继承但能被实例化的功能

这样的类只能在**堆**上构建一个对象，却不能够在**栈**上构建。最好的方法是使用虚继承

在 *C++11* 中引入了关键字 `final`，可以更简单的实现，这样 `FinalClass` 就不能被继承了

```cpp
class FinalClass final {
};
```

<a id="2-2-17"></a>

### 2.2.17 `final` 和 `override` 关键字

> [*C++11*继承控制关键字：`override` 和 `final`](https://blog.csdn.net/le119126/article/details/50175051)

重写虚函数会遇到的问题

- 无意中重写
- 签名不匹配

```cpp
struct G {
  virtual void func(int);
};
struct H: G {
  virtual void func(double); //accidentally creates a new virtual function
};
```

`override` 明确地表示一个函数是对基类中一个虚函数的重写。更重要的是，它会检查基类虚函数和派生类中重写函数的签名不匹配问题。如果签名不匹配，编译器会发出错误信息

```cpp
struct G {
  virtual void func(int);
};
struct H: G {
  virtual void func(double) override; //compilation error
};
```

`final` 类和函数

- 阻止子类继承

```cpp
class TaskManager {/*..*/} final;  
class PrioritizedTaskManager: public TaskManager {
};  //compilation error: base class TaskManager is final
```



- 阻止重写虚函数

```cpp
struct A
{
  virtual void func() const;
};
struct B: A
{
  void func() const override final; //OK
};
struct C: B
{
 void func()const; //error, B::func is final
};
```

`C::func()` 是否声明为 `override` 没关系，一旦一个虚函数被声明为 `final` ，派生类不能再重写它

<div align="right"><a href="#content">⏫</a></div>



<div STYLE="page-break-after: always;"></div>

<a id="3"></a>

# 网络编程 

<a id="3-1"></a>

## 3.1 TCP UDP 

<a id="3-1-1"></a>

### 3.1.1 TCP、UDP 的区别 `⭐⭐⭐⭐⭐`
**TCP** (Transmission Control Protocol，传输控制协议) 是一种面向连接的、可靠的、基于字节流的传输层通信协议，其传输的单位是报文段

特征：
- 面向连接
- 只能点对点 (一对一) 通信
- 可靠交互
- 全双工通信
- 面向字节流

TCP 如何保证可靠传输：
- 确认和超时重传
- 数据合理分片和排序
- 流量控制
- 拥塞控制
- 数据校验

**UDP** (User Datagram Protocol，用户数据报协议) 是 OSI (Open System Interconnection 开放式系统互联) 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，其传输的单位是用户数据报

特征：
- 无连接
- 尽最大努力交付
- 面向报文
- 没有拥塞控制
- 支持一对一、一对多、多对一、多对多的交互通信
- 首部开销小

<div align="right"><a href="#content">⏫</a></div>
<a id="3-1-2"></a>

### 3.1.2 TCP、UDP 的优缺点⭐⭐⭐

<a id="3-1-3"></a>

### 3.1.3 TCP UDP 适用场景⭐⭐⭐ 

<a id="3-1-4"></a>

### 3.1.4 TCP 为什么是可靠连接⭐⭐⭐⭐ 

<a id="3-1-5"></a>

### 3.1.5 典型网络模型，简单说说有哪些；⭐⭐⭐

<a id="3-1-6"></a>

### 3.1.6 Http1.1 和 Http1.0 的区别⭐⭐⭐ 

<a id="3-1-7"></a>

### 3.1.7 URI (统一资源标识符) 和 URL (统一资源定位符) 之间的区别⭐⭐ 
> [标识互联网上的内容](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Identifying_resources_on_the_Web)

> [What is the difference between a URI, a URL and a URN?](https://stackoverflow.com/questions/176264/what-is-the-difference-between-a-uri-a-url-and-a-urn)

***URI*** = *Uniform Resource Identifier* 统一资源标志符        
***URL*** = *Uniform Resource Locator* 统一资源定位符       
***URN*** = *Uniform Resource Name* 统一资源名称

*URI* 是抽象的定义，不管用什么方法表示，只要能定位一个资源，就叫 *URI*.       
本来设想的的使用两种方法定位：

- *URL* 用地址定位
- *URN* 用名称定位

举个例子：去村子找个具体的人 (*URI*)，如果用地址 (某村多少号房子第几间房的主人) 就是 *URL*， 如果用身份证号 + 名字去找就是 *URN* 了

结果就是目前 *WEB* 上就 *URL* 流行开了，平常见得 *URI* 基本都是 *URL*

<div align="right"><a href="#content">⏫</a></div>
<a id="3-2"></a>

## 3.2 三次握手、四次挥手 

<a id="3-2-1"></a>

### 3.2.1 什么是三次握手 `⭐⭐⭐⭐⭐`
![tcp_3](./image/tcp_3.png)

<a id="3-2-2"></a>

### 3.2.2 为什么三次握手中客户端还要发送一次确认呢?可以二次握手吗? `⭐⭐⭐⭐` 
如果两次，客户端无保证，那么 B 无法确定 B 的信息 A 是否能收到，所以如果 B 先说话，可能后面的 A 都收不到，会出现问题       
如果四次，那么就造成了浪费，因为在三次结束之后，就已经可以保证 A 可以给 B 发信息，A 可以收到 B 的信息； B 可以给 A 发信息，B 可以收到 A 的信息

- 第一次握手是为了请求建立 TCP 连接，显然是必须的
- 第二次握手是为了让客户端知道连接已经成功建立。如果没有第二次握手，假如连接建立失败，此时客户端不知情，会继续发送数据，导致出错
- 第三次握手是防止失效了的连接建立请求再次到达服务端，导致服务端试图再次建立连接，从而产生错误。所以，B 建立连接时需要再次向 A 进行确认

<div align="right"><a href="#content">⏫</a></div>
<a id="3-2-3"></a>

### 3.2.3 为什么服务端易受到 SYN 攻击? `⭐⭐⭐⭐`
TCP 三次握手在第二阶段容易受到攻击，即 SYN 泛洪攻击，如果客户机伪造出大量第一次的 SYN 同步报文，服务端就会依次消耗掉很多资源来保存客户端的信息，并进行确认，实际上确认是会失败的，但失败需要一定的时间，因为服务端会连续多次进行第二次握手确认后才认定失败。那么短时间有大量的 SYN 同步报文涌向服务端，服务端资源可能被耗尽，就可能导致正常的客户端得不到响应而失败

对于 SYN 泛洪攻击的防范，优化主机系统设置是常用的手段
- 如降低 SYN timeout 时间，使得主机尽快释放半连接的占用
- 又比如采用 SYN cookie 设置，如果短时间内连续收到某个 IP 的重复 SYN请求，则认为受到了该 IP 的攻击，丢弃来自该 IP 的后续请求报文
- 此外合理地采用防火墙等外部网络安全设施也可缓解 SYN 泛洪攻击

<div align="right"><a href="#content">⏫</a></div>
<a id="3-2-4"></a>

### 3.2.4 什么是四次挥手 `⭐⭐⭐⭐⭐`
![tcp_4](./image/tcp_4.png)

<a id="3-2-5"></a>

### 3.2.5 为什么客户端最后还要等待 2MSL? `⭐⭐⭐⭐`
- 为了保证 A 发送的最后一个 `ACK` 报文段能够到达 B。即 A 等到 2MSL 后，当出现A发送的确认报文段丢失时，可以收到B超时重传报文段，从而再次确认，使连接正常释放
- 防止 ”已失效的连接请求报文段“ 出现在本连接中。A 在发送完最后一个 `ACK` 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段

<div align="right"><a href="#content">⏫</a></div>
<a id="3-2-6"></a>

### 3.2.6 为什么建立连接是三次握手，关闭连接却是四次挥手呢? `⭐⭐⭐⭐`
四次挥手

client 先发送 `FIN` 告知对方我已经完成数据发送了，server 回复 ack 来确定我知道了。这样一个流程，就关闭了client 的发送信息通道。但是 client 仍然可以接收数据，还可以接收来自 server 方的数据。

server 此时已经知道接收不到 client 的数据了，但是还可以给它发送数据。如果 server 也没有啥数据要发送给对方了，server 也会以 `FIN` 标志位发送一个信息给 client，client 接到后，也会传递一个 ack 表示知道了。这样子，双方都完成了关闭

前两次挥手，客户端关闭发送通道，服务端确认，将未发送完数据发完；
后两次挥手，服务端关闭发送通道，客户端确认，服务端确认

<div align="right"><a href="#content">⏫</a></div>
<a id="3-3"></a>

## 3.3 应用层

> 部分参考 [HillZhang 计算机网络](https://hillzhang1999.gitee.io/2020/05/22/ji-suan-ji-wang-luo-quan-bu-fu-xi-bi-ji/#toc-heading-20)

<a id="3-3-1"></a>

### 3.3.1 DNS

#### 域名服务器类型

##### 根域名服务器
- 根域名服务器是**最高层次**的域名服务器，也是**最重要**的域名服务器。所有的根域名服务器都知道所有的**顶级域名服务器的域名和 IP 地址**
- 不管是哪一个本地域名服务器，若要对互联网上任何一个域名进行解析，只要自己无法解析，就**首先求助于根域名服务器**
- 根域名服务器共有 **13 套**装置。

##### 顶级域名服务器
- **顶级域名服务器（即 TLD 服务器）**负责管理在该顶级域名服务器注册的所有**二级域名**
- 当收到 DNS 查询请求时，就给出相应的回答（可能是最后的结果，也可能是下一步应当找的域名服务器的 IP 地址）（**迭代查询而非递归查询**）

##### 权限域名服务器
- 负责**一个区**的域名服务器。
- 当一个权限域名服务器还不能给出最后的查询回答时，就会告诉发出查询请求的 DNS 客户，**下一步应当找哪一个权限域名服务器**。

##### 本地域名服务器
- 本地域名服务器对域名系统非常重要
- 当一个主机发出 DNS 查询请求时，这个查询请求报文就**首先发送给本地域名服务器**
- 每一个互联网服务提供者 ISP，或一个大学，甚至一个大学里的系，都可以拥有一个本地域名服务器，
- 这种域名服务器有时也称为**默认域名服务器**

#### 域名解析过程

- 主机向**本地域名服务器**的查询一般都是采用**递归查询** (被请求的域名服务器若无法给出所需的 IP 地址，就以 DNS 客户的身份**帮忙**继续发送查询请求报文)
- 本地域名服务器向根域名服务器的查询通常是采用**迭代查询** (被请求的域名服务器若无法给出所需的 IP 地址，不帮忙继续发送查询请求报文，而是返回给请求者“**它下一步应当向哪一个域名服务器查询**”)

![dns](./image/dns.png)
<div align="right"><a href="#content">⏫</a></div>

<a id="3-3-2"></a>

### 3.3.2 HTTP

HTTP 是**无状态**的，之所以说无状态是因为 **HTTP 对事务没有记忆性**。**同一个客户第二次访问同一个服务器，服务器的响应结果和第一次是一样的**。HTTP 的无状态简化了服务器的设计，允许服务器支持**高并发**的 HTTP 请求。如果要解决无状态的问题，可以使用 ***cookie*** 和 ***session***

- *Cookie* 存放在**客户端的文件**中，而 *Session* 存放在**服务器端的内存**中
- *Cookie* 只能存储 **ASCII 码字符串**，而 *Session* 则可以存储**任何类型的数据**，因此在考虑数据复杂性时**首选 *Session* **
- *Cookie* 存储在**客户端的浏览器文件**中，容易被恶意查看。如果非要将一些隐私数据存在 *Cookie* 中，可以将 *Cookie* 值进行**加密**，然后在服务器进行**解密**
- 对于大型网站，如果用户所有的信息都存储在 *Session* 中，那么**开销是非常大**的，因此不建议将所有的用户信息都存储到 *Session* 中

#### HTTP1.0/1.1/2

##### HTTP1.0

- HTTP1.0默认**不支持长连接**，每一次请求都需要**重新建立TCP连接**
- HTTP1.0中认为每台服务器都绑定一个**唯一**的IP地址，因此，请求消息中的URL并没有传递**主机名 (hostname)** 。但随着虚拟主机技术的发展，在一台物理服务器上可以存在**多个虚拟主机 (Multi-homed Web Servers)**，并且它们共享一个IP地址

##### HTTP1.1

- HTTP1.1 支持**持久连接** (HTTP1.1的默认模式使用带流水线的持久连接)，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，**减少了建立和关闭连接的消耗和延迟**
- HTTP1.1 还允许客户端**不用等待**上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地**减少了整个下载过程所需要的时间**
- HTTP1.1 中增加 **Host 请求头字段** ， 实现了在一台 WEB 服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建**多个虚拟WEB站点** 
- HTTP1.1 还提供了与**身份认证、状态管理和 Cache 缓存**等机制相关的请求头和响应头 ，支持**断点续传**

##### HTTP2.0

- **header压缩**：我们在传输文本等静态资源的时候，一般会开启压缩，gzip 等，这样会减少宽带的占用，对于一些较大的文本文件，压缩后会减少的特别明显，相应也会感觉提升了很多。而 header 头信息的传输却一直使用字符串来传输，**HTTP2.0 使用 HPACK 算法对 header 的数据进行压缩**，这样数据体积小了，在网络上传输就会更快
- **服务器推送**： 当我们对支持 HTTP2.0 的 web server 请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源
- **多路复用**： 多个请求可同时在一个连接上**并行执行**。某个请求任务耗时严重，不会影响到其它连接的正常执行； 而 HTTP1.1 的长连接是若干个请求排队**串行化单线程处理**，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的**线头阻塞**

#### HTTP 请求方法

| 方法    | 描述                                                         |
| :------ | :----------------------------------------------------------- |
| GET     | 请求指定的页面信息，并返回实体主题                           |
| HEAD    | 类似 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| POST    | 向指定资源提交数据进行处理请求 (例如提交表单或上传文件)。数据被包含在请求体中。POST 请求可能会导致新资源的建立、已有资源的修改 |
| PUT     | 从客服端向服务器传送的数据取代指定的文档的内容               |
| DELETE  | 请求服务器删除指定的页面                                     |
| CONNECT | HTTP1.1 协议中预留给能够将连接改为管道方式的代理服务器       |
| OPTIONS | 允许客服端查看服务器性能                                     |
| TRACE   | 回显服务器收到的请求，主要用于测试或诊断                     |
| PATCH   | 对 PUT 方法的补充，用来对已知资源进行局部更新                |

#### GET 、POST 区别

- `GET` 方法是在浏览器的地址栏中输入网址的方式访问网页时，浏览器采用 `GET` 方法向服务器获取资源，`POST` 方法要求被请求服务器接受附在请求后面的数据，常用于提交表单。**`GET` 是用于获取数据的，`POST` 一般用于将数据发给服务器之用**
- `GET` 和 `POST` 的请求都能使用额外的参数，但是 `GET` 的参数是以**查询字符串**出现在 **URL** 中，而 `POST` 的参数**存储在实体主体 (body) **中。不能因为 `POST` 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些**抓包工具**查看。 但实际上，私密内容的传输尽量还是使用 **`POST` + Body **的形式传输，毕竟这样做参数不会明文显示在 URL 中，如果要加强传输安全性，需要使用 **HTTPS** 协议。此外，由于浏览器的限制，URL 的长度通常是**限长**的，这将导致 `GET` 方法的参数**有限**，而 `POST` 方法无限
- 针对**服务器**来说，安全的 HTTP 方法**不会改变服务器状态**，也就是说它只是**可读**的。`GET` 方法是安全的，而 `POST` 却不是，因为 `POST` 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变
- `GET` 方法是**幂等**的，而 `POST` 方法**不幂等**。所谓幂等指的是**同一个请求方法执行多次和仅执行一次的效果完全相同**

#### HTTP 状态码

| 分类 | 描述                                           |
| ---- | ---------------------------------------------- |
| 1XX  | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2XX  | 成功，操作被成功接受并处理                     |
| 3XX  | 重定向，需要进一步的操作以完成请求             |
| 4XX  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5XX  | 服务器错误，服务器在处理请求的过程中发生了错误 |

<div align="right"><a href="#content">⏫</a></div>

<a id="3-3-3"></a>

### 3.3.3 HTTPS

HTTP 有很大的安全隐患：**使用明文进行通信**，内容可能会被窃听。**不验证通信方的身份**，通信方的身份有可能遭遇伪装。**无法证明报文的完整性**，报文有可能遭篡改

HTTPS 是以**安全**为目标的 HTTP 通道，S 代表 *security*，让 HTTP 先和 SSL 通信，再由 SSL 和 TCP 通信，也就是说 HTTPS使用了隧道进行通信。通过使用 SSL，HTTPS 具有了加密 (防窃听)、认证 (防伪装) 和完整性保护 (防篡改)

#### 加密算法
加密算法主要有对称加密和非对称加密
- 对称加密的运算速度快，但安全性不高
- 非对称密钥加密，加密和解密使用不同的密钥。公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密

非对称密钥除了用来加密还可以用来进行**签名**。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。非对称加密的运算速度慢，但是更安全

**HTTPS 采用混合的加密机制**，使用**非对称密钥加密**用于传输对称密钥来保证传输过程的**安全性**，之后使用**对称密钥加密**进行通信来保证通信过程的**效率**

#### 流程

- 请求证书。浏览器和服务器建立 TCP 连接后，会发送一个**证书请求**，其中包含了自己可以实现的算法列表和一些必要信息，用于商议双方使用的加密算法
- 发还证书。服务器收到请求后会**选择加密算法**，然后返回**证书**，包含了服务器的信息，域名、申请证书的公司、加密的公钥以及加密的算法等
- 公钥加密。浏览器收到之后，检查签发该证书的机构是否正确，该机构的公钥签名是否有效，如果有效就生成对称密钥，并利用**公钥**对其加密，然后发送给服务器
- 私钥解密，创建安全连接。服务器收到密钥后，利用自己的**私钥**解密。之后浏览器和服务器就可以基于**对称加密**对数据进行加密和通信 (**建立连接是非对称加密，传输数据是对称加密，兼顾效率和安全性**)

![https](./image/https.png)

<div align="right"><a href="#content">⏫</a></div>

<div STYLE="page-break-after: always;"></div>

<a id="4"></a>

# 常见算法 

<a id="4-1"></a>

## 4.1 排序算法 

<a id="4-1-1"></a>

### 4.1.1各种排序算法的时间空间复杂度、稳定性 `⭐⭐⭐⭐⭐`

> [附录-排序算法](#sort-algorithm)

排序算法 | 平均时间复杂度 | 最差时间复杂度 | 空间复杂度 | 数据对象稳定性
---|---|---|---|---
[冒泡排序](algorithm/BubbleSort.h) | O(n<sup>2</sup>)|O(n<sup>2</sup>)|O(1)|稳定
[选择排序](algorithm/SelectionSort.h) | O(n<sup>2</sup>)|O(n<sup>2</sup>)|O(1)|数组不稳定、链表稳定
[插入排序](algorithm/InsertSort.h) | O(n<sup>2</sup>)|O(n<sup>2</sup>)|O(1)|稳定
[快速排序](algorithm/QuickSort.h) | O(n*log<sub>2</sub>n) |  O(n<sup>2</sup>) | O(log<sub>2</sub>n) | 不稳定
[堆排序](algorithm/HeapSort.h) | O(n*log<sub>2</sub>n)|O(n*log<sub>2</sub>n)|O(1)|不稳定
[归并排序](algorithm/MergeSort.h) | O(n*log<sub>2</sub>n) | O(n*log<sub>2</sub>n)|O(n)|稳定
[希尔排序](algorithm/ShellSort.h) | O(n*log<sup>2</sup>n)|O(n<sup>2</sup>)|O(1)|不稳定
[计数排序](algorithm/CountSort.h) | O(n+m)|O(n+m)|O(n+m)|稳定
[桶排序](algorithm/BucketSort.h) | O(n)|O(n)|O(m)|稳定
[基数排序](algorithm/RadixSort.h) | O(k*n)|O(n<sup>2</sup>)| |稳定

> * 均按从小到大排列
> * k：代表数值中的 “数位” 个数
> * n：代表数据规模
> * m：代表数据的最大值减最小值

<div align="right"><a href="#content">⏫</a></div>
<a id="4-1-2"></a>

### 4.1.2各种排序算法什么时候有最好情况、最坏情况 `⭐⭐⭐⭐`



<a id="4-2"></a>

## 4.2 `STL` 库相关

<a id="4-2-1"></a>

### 4.2.1 `vector` `list`异同⭐⭐⭐⭐⭐ 

<a id="4-2-2"></a>

### 4.2.2 `vector` 内存是怎么增长的 ⭐⭐⭐⭐ 

<a id="4-2-3"></a>

### 4.2.3 `vector` 和 `deque` 的比较⭐⭐⭐⭐ 

<a id="4-2-4"></a>

### 4.2.4 `sort` ⭐⭐⭐ 

<a id="4-2-5"></a>

### 4.2.5 `STL` 底层数据结构实现⭐⭐⭐⭐ 

<a id="4-2-6"></a>

### 4.2.6 利用迭代器删除元素会发生什么? ⭐⭐⭐⭐ 

<a id="4-2-7"></a>

### 4.2.7 `map` 是如何实现的，查找效率是多少⭐⭐⭐⭐⭐ 

<a id="4-2-8"></a>

### 4.2.8 几种模板插入的时间复杂度 ⭐⭐⭐⭐⭐ 

<div STYLE="page-break-after: always;"></div>

<a id="5"></a>

# Linux操作系统 

<a id="5-1"></a>

## 5.1 Linux内核相关 
### 5.1.1 Linux内核的组成⭐⭐ 
### 5.1.2 用户空间与内核通信方式有哪些？⭐⭐⭐⭐⭐ 
### 5.1.3 系统调用 read()/write()，内核具体做了哪些事情⭐⭐ 
### 5.1.4 系统调用的作用⭐⭐⭐⭐⭐ 
### 5.1.5 内核态，用户态的区别⭐⭐⭐⭐⭐ 
### 5.1.6 bootloader 内核 根文件的关系⭐⭐⭐⭐ 
### 5.1.7 Bootloader 多数有两个阶段的启动过程：⭐⭐⭐ 
### 5.1.8 linux 的内核是由 bootloader 装载到内存中的？⭐⭐⭐ 
### 5.1.9 为什么需要 BootLoader⭐⭐⭐⭐ 
### 5.1.10 Linux 内核同步方式总结⭐⭐⭐⭐ 
### 5.1.11 为什么自旋锁不能睡眠 而在拥有信号量时就可以？⭐⭐⭐⭐ 
### 5.1.12 linux 下检查内存状态的命令⭐⭐⭐ 

<a id="5-2"></a>

## 5.2 其他操作系统 

<a id="5-2-1"></a>

### 5.2.1 大小端 `⭐⭐⭐⭐⭐` 

- 大端：高位存储在低地址
- 小端：高位存储在高地址

```cpp
bool isBigEndian1() {
    int a = 0x1234;
    // char c = *(char*)(&a);
    char c = static_cast<char>(a);
    if (c == 0x12) 
        return true;
    return false;
}
bool isBigEndian2() {
    union NUM
    {
        int a;
        char c;
    } num;
    num.a = 0x1234;
    if (num.c == 0x12)
        return true;
    return false;
}
```



<div align="right"><a href="#content">⏫</a></div>
<a id="5-2-2"></a>

### 5.2.2 一个程序从开始运行到结束的完整过程 (四个过程) `⭐⭐⭐⭐⭐` 
### 5.2.3 什么是堆，栈，内存泄漏和内存溢出？⭐⭐⭐⭐ 
### 5.2.4 堆和栈的区别⭐⭐⭐⭐⭐ 
### 5.2.5 死锁的原因、条件 创建一个死锁，以及如何预防⭐⭐⭐⭐⭐ 
### 5.2.6 硬链接与软链接的区别；⭐⭐⭐⭐⭐ 
### 5.2.7 虚拟内存，虚拟地址与物理地址的转换⭐⭐⭐⭐ 
### 5.2.8 计算机中，32bit 与 64bit 有什么区别⭐⭐⭐ 
### 5.2.9 中断和异常的区别⭐⭐⭐⭐⭐ 
### 5.2.10 中断怎么发生，中断处理大概流程⭐⭐⭐⭐ 
### 5.2.11 Linux 操作系统挂起、休眠、关机相关命令⭐⭐ 


<div STYLE="page-break-after: always;"></div>

<a id="6"></a>

# 其他

<a id="6-1"></a>

## 6.1 编程语言

<a id="6-1-1"></a>

### 6.1.1 垃圾回收机制算法

#### 引用计数

*reference counting* 基本思路是为每个对象加一个计数器，记录指向这个对象的引用数量。每次有一个新的引用指向这个对象，计数器加一；反之每次有一个指向这个对象引用被置空或者指向其他对象，计数器减一。当计数器变为 0 的时候，自动删除这个对象

- 及时回收，没有延迟。对象在成为垃圾的瞬间会被释放，不会给程序的正常执行带来额外的中断
- 相对简单，不需要太多运行时的支持，可以在原生不支持 `GC` 的语言里实现 
- 需要单独的字段存储计数器，增加存储空间的开销
- 每次赋值都需要更新计数器，增加时间开销
- 不能解决循环引用的问题

#### 标记-清除

*mark-sweep* 基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放

- 能够处理循环引用的问题
- ”停止-启动“，在垃圾回收器运行过程中，应用程序必须暂时停止
- 在标记阶段需要遍历所有的存活对象，会造成一定开销
- 清除垃圾对象后会造成大量内存碎片

#### 节点复制

*coping* 基本思路是把整个内存空间一分为二 (`From`, `To`)，所有对象的内存在 `From` 中分配，当 `From` 塞满的时候，同样从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象复制到 `To` 去，然后对调 `From` 和 `To` 的角色

- 解决内存碎片。所有的对象在内存中永远都是紧密排列的，所以分配内存的任务变得极为简单，只要移动一个指针即可
- 由于不需要清扫整个内存空间，所以如果内存中存活对象很少而垃圾对象很多的话，触发 GC 造成的中断时间会小于**标记-清扫**
- 空间换时间

#### 分代收集

*Generational Collection* 核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法

目前大部分垃圾收集器对于新生代都采取 *Copying* 算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少；而由于老年代的特点是每次回收都只回收少量对象，一般使用的是标记清除算法

<div align="right"><a href="#content">⏫</a></div>
<a id="6-2"></a>

## 6.2 Git

> [Git Book](https://git-scm.com/book/en/v2)

<a id="6-2-1"></a>

### 6.2.1 rebase
`Git` 中整合来自不同分支的修改主要有两种方法，`merge` 和 `rebase`

整合分支最容易的方法是 `merge` 命令。他会把两个分支的最新快照 (`C3` 和 `C4`) 以及二者最近的共同祖先 (`C2`) 进行三方合并，合并的结果是生成一个新的快照  (并提交)

<a id="merge-example"></a>

![merge](./image/git/merge.png)

其实，还有一种方法：可以提取在 `C4` 中引入的修改，然后在 `C3` 的基础上应用一次。这种操作就叫做 `rebase`。使用 `rebase` 命令将提交到某一分支的所有修改都移至另一分支上，就好像 *重新播放* 一样

例子，切到 `experiment` 分支，然后将它变基到 `master` 分支上：

```shell
$ git checkout experiment
$ git rebase master

```

原理是首先找到这两个分支 (即当前分支 `experiment` 、变基操作的目标基底分支 `master`) 的最近公共祖先 `C2`，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并保存为临时文件，然后将当前分支指向目标基底 `C3`，最后以此将之前另存为临时文件的修改依次应用

![rebase](./image/git/rebase.png)

将 `C4` 中的修改变基到 `C3`上

现在回到 `master` 分支，进行一次快进合并

```shell
$ git checkout master
$ git merge experiment
```

![rebase-merge](./image/git/rebase-merge.png)

此时，`C4'` 指向的快照就和 [the merge example](#merge-example) 中的 `C5` 指向的快照一模一样了。这两种整合方法的最终结果没有任何区别，但是变基使得提交历史更加整洁。 你在查看一个经过变基的分支的历史记录时会发现，尽管实际的开发工作是并行的， 但它们看上去就像是串行的一样，提交历史是一条直线没有分叉

一般我们这样做的目的是为了确保在向远程分支推送时能保持提交历史的整洁——例如向某个其他人维护的项目贡献代码时。 在这种情况下，你首先在自己的分支里进行开发，当开发完成时你需要先将你的代码变基到 `origin/master` 上，然后再向主项目提交修改。 这样的话，该项目的维护者就不再需要进行整合工作，只需要快进合并便可

请注意，无论是通过变基，还是通过三方合并，整合的最终结果所指向的快照始终是一样的，只不过提交历史不同罢了。 变基是将一系列提交按照原有次序依次应用到另一分支上，而合并是把最终结果合在一起

**原则**：只对尚未推送或分享给别人的本地修改执行变基操作清理历史， 从不对已推送至别处的提交执行变基操作

<div align="right"><a href="#content">⏫</a></div>

<a id="6-3"></a>

## 6.3 Python

<a id="6-3-1"></a>

### 6.3.1 `is` 与 `==` 区别

- `is` 比较两个对象的 `id` 值是否相等，是否指向同一个内存地址
- `==` 比较的是两个对象的内容是否相等，值是否相等
- 小整数对象 `[-5, 256]` 在全局解释器范围内被放入缓存供重复使用
- `is` 运算符比 `==` 效率高，在变量和 `None` 进行比较时，应该使用 `is`

<a id="6-3-2"></a>

### 6.3.2 迭代器、生成器

#### 可迭代对象

可以直接作用于 `for` 循环的数据类型

- 一类是集合数据类型，如 `list`、`tuple`、`dict`、`set`、`str` 等
- 一类是 `generator` ，包括生成器和带 `yield` 的 *generator function*

这些可以直接作用于 `for` 循环的对象统称为可迭代对象：`Iterable`

可以使用 `isinstance()` 判断一个对象是否是 `Iterable` 对象

```python
from collections import Iterable
print(isinstance('abc', Iterable))
```

生成器不但可以作用于 `for` 循环，还可以被 `next()` 函数不断调用并返回下一个值，直到最后抛出 `StopIteration` 错误，表示无法继续返回下一个值了

#### 迭代器

可以被 `next()` 函数调用并不断返回下一个值得对象称为迭代器 (`Iterator`)

使用 `isinstance()` 判断一个对象是否是 `Iterator` 对象

```python
from collections import Iterator
print(isinstance((x for x in range(5)), Iterator))
```

`list`、`dict`、`str` 虽然是 `Iterable`，却不是 `Iterator`

可以使用 `iter()` 函数把 `list`、`dict`、`str` 等 `Iterable` 变成 `Iterator`

```python
print(isinstance(iter('abc'), Iterator))
```



#### 生成器

一边循环一边计算得机制，称为生成器 (`generator`)

##### 为什么要有生成器

如果只需要访问列表前面的元素，那后面绝大多数元素占用的空间就都浪费了

如果列表元素按照某种算法推算出来，那就可以在循环的过程中不断推算出后续的元素，这样就不必创建完整的列表，从而节省大量的空间

##### 创建生成器

把列表生成式的 `[]` 改为 `()`

```python
L = [x * x for x in range(5)]
G = (x * x for x in range(5))
```

如果一个函数中包括 `yield` 关键字，调用这个函数就是创建了一个生成器对象

<div align="right"><a href="#content">⏫</a></div>

### 6.3.3 装饰器



### 6.3.4 GIL



<a id="6-3-5"></a>

### 6.3.5 协程

> [使用](https://www.jianshu.com/p/7c851145ee4c)

协程又称微线程，***Coroutine***，是一种用户态的轻量级线程

协程不同于进程，线程是抢占式的调度，而协程是协同式的调度，也就是说协程需要自己做调度。对于线程和进程，调度是由 *CPU* 来决定调度的，而协程是由程序员决定

在其他语言中，协程的意义不大，多线程即可解决 `I/O` 问题，但是在 *Python* 中因为 `GIL` 的存在，导致同一时间只有一个线程在工作

#### 优点

- 无需线程上下文切换的开销
- 无需原子操作锁定以及同步的开销
- 方便切换控制流，简化编程模型

#### 缺点

无法利用多核资源：协程本质是个单线程，不能同时将单个 *CPU* 的多个核用上。协程需要和进程配合才能运行在多 *CPU*上，不过这种情况多用于 *CPU* 密集型任务

进行阻塞操作时会阻塞整个程序

<div align="right"><a href="#content">⏫</a></div>

<a id="6-4"></a>

## 6.4 MySql

<a id="6-4-1"></a>

### 6.4.1 基本概念

#### 键

**超键**

在关系中能**唯一标识元组的属性**集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键

**候选键**

是最小超键，即没有冗余元素的超键

**主键**

数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值 (Null)

**外键**

在一个表中存在的另一个表的主键称此表的外键

#### 触发器

触发器是一种特殊的存储过程，主要是**通过事件来触发而被执行**的。它可以强化约束，**来维护数据的完整性和一致性**，可以跟踪数据库内的操作从而不允许未经许可的更新和变化

可以**联级运算**。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发

#### 存储过程

存储过程是**一个预编译的 `SQL` 语句**，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次 `SQL`，使用存储过程比单纯 `SQL` 语句执行要快

调用：

- 可以用一个命令对象来调用存储过程
- 可以供外部程序调用

优点：

- 存储过程是预编译过的，**执行效率高**
- 存储过程的代码**直接存放于数据库中，通过存储过程名直接调用**，减少网络通讯
- **安全性高**，执行存储过程需要有一定权限的用户
- 存储过程**可以重复使用**，可减少数据库开发人员的工作量

缺点：

- 移植性差

与函数的区别：

- 

#### 视图

是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，**视图通常是有一个表或者多个表的行或列的子集**。对视图的修改会影响基本表。相比多表查询，它使得我们获取数据更容易

优点：

- 使用视图，可以定制用户数据，聚焦特点的数据
- 简化数据操作
- 维护数据的独立性
- 对于相同数据可产生不同的视图

缺点：

- 性能差
- 修改限制

**哪类视图可以更新？**

一般的行列子集视图是可以更新的

视图的字段来自字段表达式或常数，视图的字段来自聚集函数，视图的定义中含有 `Group By` 子句，视图的定义中含有 `DISTINCT` 短语，视图定义中有嵌套查询，则视图不能更新

> [临时表和视图的区别](https://blog.csdn.net/libinhai110/article/details/80165923)

#### 临时表

临时表只在当前连接可见，当关闭连接时，`MySQL` 会自动删除表并释放所有空间。因此在不同的连接中可以创建同名的临时表，并且操作属于本连接的临时表。创建临时表的语法与创建表语法类似，不同之处是增加关键字 `TEMPORARY`，如：
```sql
CREATE  TEMPORARY TABLE tmp_table (
 NAME VARCHAR (10) NOT NULL,
 time date NOT NULL
 );
 select * from tmp_table;
```
临时表可以手动删除：
```sql
DROP TEMPORARY TABLE IF EXISTS temp_tb;
```

#### 范式

**第一范式**

(确保每列保持原子性) 所有字段值都是不可分解的原子值

**第二范式**

(确保表中的每列都和主键相关) 在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中

**第三范式**

(确保每列都和主键列直接相关,而不是间接相关) 数据表中的每一列数据都和主键直接相关，而不能间接相关

**BCNF**

符合 *3NF*，并且，主属性不依赖于主属性

**第四范式**

要求把同一表内的多对多关系删除

**第五范式**

从最终结构重新建立原始结构

#### 连接类型

**内连接**

只连接匹配的行 (`INNER JOIN`)

**左外连接**

包含左边表的全部行 (不管右边的表中是否存在与它们匹配的行)，以及右边表中全部匹配的行 (`LEFT JOIN`)

**右外连接**

 包含右边表的全部行 (不管左边的表中是否存在与它们匹配的行)，以及左边表中全部匹配的行 (`RIGHT JOIN`)

**全外连接** 

包含**左、右两个表的全部行**，不管另外一边的表中是否存在与它们匹配的行 (`FULL OUT JOIN`)

**交叉连接**

生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将**一个数据源中的每个行与另一个数据源的每个行都一一匹配** (`CROSS JOIN`)





<div align="right"><a href="#content">⏫</a></div>



<a id="6-4-2"></a>

### 6.4.2 *Innodb* 中的事务隔离级别和锁的关系

> [美团-文章](https://tech.meituan.com/2014/08/20/innodb-lock.html)

#### 事务的隔离级别

- 未提交读 (***Read Uncommitted***)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据
- 提交读 (***Read Committed***)：只能读取到已经提交的数据。***Oracle*** 等多数数据库默认都是该级别 (不重复读)
- 可重复读 (***Repeated Read***)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，***InnoDB*** 默认级别。在 `SQL` 标准中，该隔离级别消除了不可重复读，但是还存在幻象读
- 串行读 (***Serializable***)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞

***Read Uncommitted*** 这种级别，数据库一般都不会用，而且任何操作都不会加锁

| 隔离级别 | 脏读 (Dirty Read) | 不可重复读 (NonRepeatable) | 幻读 (Phantom Read) |
| -------- | ----------------- | -------------------------- | ------------------- |
| 未提交读 | 可能              | 可能                       | 可能                |
| 已提交读 | 不可能            | 可能                       | 可能                |
| 可重复读 | 不可能            | 不可能                     | 可能                |
| 可串行化 | 不可能            | 不可能                     | 不可能              |



#### 事务的并发问题

##### 脏读

事务 *A* 读取了事务 *B* 更新的数据，然后 *B* 回滚操作，那么 *A* 读取到的数据是脏数据

##### 不可重复读

事务 *A* 多次读取同一数据，事务 *B* 在事务 *A* 多次读取的过程中，对数据作了**更新**并提交，导致事务 *A* 多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致

##### 幻读

一个事务 (同一个read view) 在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行

#### 不可重复读和幻读的区别

不可重复读重点在于 `update` 和 `delete`，而幻读的重点在于 `insert`

如果使用锁机制来实现这两种隔离级别，在可重复读中，该 `sql` 第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住 `insert` 的数据，所以当事务 *A* 先前读取了数据，或者修改了全部数据，事务 *B* 还是可以 `insert` 数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要 ***Serializable*** 隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力

所以说不可重复读和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题

#### 悲观锁和乐观锁

##### 悲观锁

指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。

在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据

##### 乐观锁

相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。

而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本 (*Version*) 记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “*version*” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据

#### 快照读和当前读

在 `RR` 级别中，通过 `MVCC` (多版本并发控制) 机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据！这在一些对于数据的时效特别敏感的业务中，就很可能出问题。

对于这种读取历史数据的方式，我们叫它快照读 (***snapshot read***)，而读取数据库当前版本数据的方式，叫当前读 (***current read***)。很显然，在 `MVCC` 中：

- 快照读，就是 `select`
    - `select * from table ...`
- 当前读，特殊的读操作、插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁
    - `select * from table where ? lock in share mode`
    - `select * from table where ? for update`
    - `insert`
    - `update`
    - `delete`

#### Next-Key 锁

***Next-Key*** 锁是行锁和 ***GAP*** (间隙锁) 的合并

行锁防止别的事务修改或删除，*GAP* 锁防止别的事务新增，行锁和 *GAP* 锁结合形成的的 *Next-Key* 锁共同解决了 `RR` 级别在写数据时的幻读问题

#### Serializable

这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差



<div align="right"><a href="#content">⏫</a></div>

<a id="6-4-3"></a>

### 6.4.3 索引

数据库索引，是**数据库管理系统中一个排序的数据结构**，索引的实现通常使用 ***Hash*** 索引、***B*** 树及其变种 ***B+*** 树

在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用 (指向) 数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引

#### 索引类型

**普通索引**

最基本的索引，没有任何限制

**唯一索引**

与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值

**主键索引**

是一种**特殊的唯一索引**，**不允许有空值**。一般是在建表的时候同时创建主键索引

**组合索引**

为了进一步榨取 `MySQL` 的效率，就要考虑建立组合索引。遵循**最左前缀原则**

#### 聚集索引

聚集索引并不是一种单独的索引类型，而是一种数据存储方式。

当表有聚集索引时，它的数据行实际上存放在索引的叶子页 (*leaf Page*) 中。因为无法同时把数据存放在两个不同的地方，所以一个表只能有一个聚集索引 (不过，覆盖索引可以模拟多个聚集索引的情况)

整个表变成了一个索引，也就是所谓的“聚集索引”。这就是为什么一个表只能有一个主键，一个表只能有一个“聚集索引”

聚集的数据有一些重要的优点

- 可以把相关数据保存在一起
- 数据访问更快
- 使用覆盖索引扫描的查询可以直接使用页节点中的主键值

聚集索引的缺点

- 更新聚集索引列的代价很高，因为会强制 *InnoDB* 将每个更新的行移动到新的位置
- 基于聚集索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临“页分裂 (*page split*)” 的问题。页分裂会导致表占用更多的磁盘空间

#### 覆盖索引

有一种例外可以不使用聚集索引就能查询出所需要的数据， 这种非主流的方法 称之为 “覆盖索引” 查询， 也就是平时所说的**复合索引或者多字段索引查询**。当为字段建立索引以后，**字段中的内容会被同步到索引之中**， 如果为一个索引指定两个字段，那么这个两个字段的内容都会被同步至索引之中

**例子**

先看下面这个 `SQL` 语句

``` sql
-- 建立索引
create index index_birthday on user_info(birthday);
-- 查询生日在1991年11月1日出生用户的用户名
select user_name from user_info where birthday = '1991-11-1'
```

 `SQL` 语句的执行过程如下

- 首先，通过**非聚集索引 `index_birthday` 查找 `birthday` 等于 `1991-11-1` 的所有记录的主键 `ID` 值**
- 然后，通过得到的**主键 `ID` 值执行聚集索引查找**，找到主键 `ID` 值对就的真实数据 (数据行) 存储的位置
- 最后，从得到的真实数据中取得 `user_name` 字段的值返回，也就是取得最终的结果

把 `birthday` 字段上的索引改成双字段的覆盖索引

```sql
create index index_birthday_and_user_name on user_info(birthday, user_name);
```

`SQL` 语句的执行过程就会变为

- 通过非聚集索引 `index_birthday_and_user_name` 查找 `birthday` 等于 `1991-11-1` 的叶节点的内容

然而，叶节点中除了有 `user_name` 表主键 `ID` 的值以外，`user_name` 字段的值也在里面，因此不需要通过主键 `ID` 值的查找数据行的真实所在，直接取得叶节点中 `user_name` 的值返回即可

通过这种覆盖索引直接查找的方式， 可以省略不使用覆盖索引查找的后面两个步骤，大大的提高了查询性能

<div align="right"><a href="#content">⏫</a></div>

<a id="6-4-4"></a>

### 6.4.4 B 树和 B+ 树

#### B 树

每个节点都存储 *key* 和 *data*，所有节点组成这棵树，并且叶子节点指针为 *nul*，叶子结点不包含任何关键字信息

#### B+ 树

所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接，所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大 (或最小) 关键字。 (而 *B* 树的非终节点也包含需要查找的有效信息)

#### B+ 树优点

**为什么说 *B+* 树比 *B* 树更适合实际应用中操作系统的文件索引和数据库索引？**

- *B+* 树的磁盘读写代价更低

***B+* 树的内部结点并没有指向关键字具体信息的指针**。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说 *IO* 读写次数也就降低了。

- *B+* 树的查询效率更加稳定

由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。**所以任何关键字的查找必须走一条从根结点到叶子结点的路**。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当



<div align="right"><a href="#content">⏫</a></div>

<a id="6-5"></a>

## 6.5 Redis

> [参考](https://blog.csdn.net/Butterfly_resting/article/details/89668661)

<a id="6-5-1"></a>

### 6.5.1 数据类型

**`string`**

`string` 类型是二进制安全的。意思是 *redis* 的 `string` 可以包含任何数据，比如 *jpg* 图片或序列化的对象。`string` 类型是 *redis* 最基本的数据类型，一个键最大能存储 512 MB

**`hash`**

`hash` 是一个键值对集合。是一个 `string` 类型的 *field* 和 *value* 的映射表

**`list`**

`list` 是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部 (左边) 或尾部 (右边)

**`set`**

`set` 是 `string` 类型的无序集合

**`zset`**

`zset` 和 `set` 一样也是 `string` 类型元素的集合，且不允许重复的成员。不同的是每个元素都会关联一个 `double` 类型的分数。*redis* 通过分数来为集合中的成员进行从小到大的排序

`zset` 成员是唯一的，但分数 (*score*) 却可以重复

<div align="right"><a href="#content">⏫</a></div>

<a id="6-5-2"></a>

### 6.5.2 持久化机制

*Redis* 是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当 *Redis* 重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的

**实现**：单独创建 `fork()` 一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。

**`RDB`** (*Redis DataBase*)

`RDB` 是 *Redis* 默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即 *Snapshot* 快照存储，对应产生的数据文件为 `dump.rdb`，通过配置文件中的 `save` 参数来定义快照的周期

**`AOF`** (*Append-only file*)

*Redis* 会将每一个收到的写命令都通过 `Write` 函数追加到文件最后，类似于 `MySQL` 的 `binlog`。当 *Redis* 重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容
当两种方式同时开启时，数据恢复 *Redis* 会优先选择 `AOF` 恢复

**比较**

- `AOF` 文件比 `RDB` 更新频率高，优先使用 `AOF` 还原数据
- `AOF` 比 `RDB` 更安全也更大
- `RDB` 性能比 `AOF` 好
- 如果两个都配了优先加载 `AOF`

<div align="right"><a href="#content">⏫</a></div>

<a id="6-5-3"></a>

### 6.5.3 缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等

#### 缓存雪崩

是指在某一个时间段，缓存集中过期失效

例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期，所有原本应该访问缓存的请求都去查询数据库了，而对数据库、*CPU* 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃

**解决方法**

- 考虑用加锁 (最多的解决方案) 或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上
- 还有一个简单方案就是将缓存失效时间分散开

#### 缓存穿透

是指查询一个数据库一定不存在的数据

正常的使用缓存流程大致是，数据查询先进行缓存查询，如果 `key` 不存在或者 `key` 已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存

**解决方法**

- 最常见的则是采用**布隆过滤器**，将所有可能存在的数据哈希到一个足够大的 `bitmap` 中，一个一定不存在的数据会被这个 `bitmap` 拦截掉，从而避免了对底层存储系统的查询压力
- 另外也有一个更为**简单粗暴的方法**，如果一个查询返回的数据为空 (不管是数据不存在，还是系统故障)，我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴

#### 缓存击穿

是指一个 `key` 非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个 `key` 在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞

**解决方法**

- 在访问 `key` 之前，采用 `SETNX` (*set if not exists*)来设置另一个短期 `key` 来锁住当前 `key` 的访问，访问结束再删除该短期 `key`

#### 缓存预热

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据

- 直接写个缓存刷新页面，上线时手工操作
- 数据量不大，可以在项目启动的时候自动进行加载
- 定时刷新缓存

#### 缓存更新

除了缓存服务器自带的缓存失效策略之外 (*Redis* 默认的有 6 种策略可供选择)，我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：

- 定时去清理过期的缓存
- 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存

两者各有优劣，第一种的缺点是维护大量缓存的 `key` 是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂

#### 缓存降级

当访问量剧增、服务出现问题 (如响应时间慢或不响应) 或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级
降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的 (如加入购物车、结算)
以参考日志级别设置预案：

- 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级
- 警告：有些服务在一段时间内成功率有波动 (如在95~100%之间)，可以自动降级或人工降级，并发送告警
- 错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级
- 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级

服务降级的目的，是为了防止 *Redis* 服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，*Redis* 出现问题，不去数据库查询，而是直接返回默认值给用户

<div align="right"><a href="#content">⏫</a></div>

<a id="6-5-4"></a>

### 6.5.4 Memcache 与 Redis 的区别



<a id="6-5-5"></a>

### 6.5.5 单线程的 Redis

因为 *Redis* 是基于内存的操作， *CPU* 不是 *Redis* 的瓶颈，*Redis* 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 *CPU* 不会成为瓶颈，那就顺理成章地采用单线程的方案了 (笔记采用多线程会有很多麻烦)，*Redis* 利用队列技术将并发访问变为串行访问

- 纯内存操作
- 单线程操作，避免了频繁的上下文切换
- 采用了非阻塞 *I/O* 多路复用机制

<div align="right"><a href="#content">⏫</a></div>

<a id="6-5-6"></a>

### 6.5.6 过期策略和内存淘汰机制

*Redis* 采用的是**定期删除 + 惰性删除策略**

**为什么不用定时删除策略?**

定时删除，用一个定时器来负责监视 `key`，过期则自动删除。虽然内存及时释放，但是十分消耗 *CPU* 资源。在大并发请求下，*CPU* 要将时间应用在处理请求，而不是删除 `key`，因此没有采用这一策略

**定期删除 + 惰性删除是如何工作的呢?**

定期删除，*redis* 默认每隔 100ms 检查，是否有过期的 `key`，有过期 `key` 则删除。需要说明的是，*redis* 不是每隔 100ms 将所有的 `key` 检查一次，而是随机抽取进行检查 (如果每隔 100ms，全部 `key` 进行检查，*redis* 岂不是卡死)。因此，如果只采用定期删除策略，会导致很多 `key` 到时间没有删除

于是，惰性删除派上用场。也就是说在获取某个 `key` 的时候，*redis* 会检查一下，这个 `key` 如果设置了过期时间，会判断是否过期，如果过期了此时就会删除

**采用定期删除+惰性删除就没其他问题了么?**

不是的，如果定期删除没删除 `key`，然后也没即时去请求 `key`，也就是说惰性删除也没生效。这样，*redis* 的内存会越来越高，那么就应该采用内存淘汰机制

- `volatile-lru`：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
- `volatile-ttl`：从已设置过期时间的数据集中挑选将要过期的数据淘汰
- `volatile-random`：从已设置过期时间的数据集中任意选择数据淘汰
- `allkeys-lru`：从数据集中挑选最近最少使用的数据淘汰
- `allkeys-random`：从数据集中任意选择数据淘汰
- `no-enviction` (驱逐)：禁止驱逐数据，新写入操作会报错

如果没有设置 `expire` 的 `key`，不满足先决条件 (*prerequisites*)，那么 `volatile-lru`、`volatile-random` 和 `volatile-ttl` 策略的行为, 和 `noeviction` 基本上一致

<div align="right"><a href="#content">⏫</a></div>

<a id="6-5-7"></a>

### 6.5.7 内部结构

> [redis 数据类型及其内部数据结构](https://www.jianshu.com/p/f8ccf8806095)
>
> [redis 数据类型](https://www.cnblogs.com/hunternet/tag/Redis/)

`string` 类型在 *Redis* 底层可以是 `int`, `raw` 和 `embstr`

`list` 类型在 *Redis* 底层可以是 `ziplist` (压缩列表) 或 `linkedlist` (双向列表)

`hash` 类型在 *Redis* 底层可以是 `ziplist` (压缩列表) 或 `hashtable` (Hash表)

`set` 类型在 *Redis* 底层可以是 `intset` (整数集合) 或 `hashtable` (Hash表)，只有当Set中的所有元素均为整数类型时才会使用 `intset`

`zset` 类型在 *Redis* 底层可以是 `ziplist` (压缩列表) 或 `skiplist` (跳跃表)

#### 跳跃表








<div align="right"><a href="#content">⏫</a></div>




<div STYLE="page-break-after: always;"></div>

<a id="appendix"></a>

# 附录

<a id="sort-algorithm"></a>

## 排序算法

- [冒泡排序](#bubble-sort)
- [选择排序](#selection-sort)
- [插入排序](#insert-sort)
- [快速排序](#quick-sort)
- [堆排序](#heap-sort)
- [归并排序](#merge-sort)
- [希尔排序](#shell-sort)
- [计数排序](#count-sort)
- [桶排序](#bucket-sort)
- [基数排序](#radix-sort)

<div align="right">
    <a href="#content">⏫</a><a href="#4-1-1">↩️</a>
</div>
<a id="bubble-sort"></a>

### BubbleSort

```cpp
/*
(无序区, 有序区). 从无序区通过交换找出最大元素放到有序区前端.
*/

// 冒泡排序
void BubbleSort(vector<int>& nums) {
    int len = nums.size();
    for (int i = 0; i < len - 1; ++i)
        for (int j = 0; j < len - 1 - i; ++j)
            if (nums[j] > nums[j + 1])
                swap(nums[j], nums[j + 1]);
}

// 冒泡排序改进版
// 如果进行某一趟排序时没有数据交换，则说明数据已经按要求排序好
// 可立即结束排序，避免不必要的比较过程
void BubbleSortOrderly(vector<int>& nums) {
    int len = nums.size();
    bool orderly = false;
    for (int i = 0; i < len - 1 && !orderly; ++i) {
        orderly = true;
        for (int j = 0; j < len - 1 - i; ++j) {
            if (nums[j] > nums[j + 1]) {
                orderly = false;
                swap(nums[j], nums[j + 1]);
            }
        }
    }
}
// 模板
// 看情况重载 运算符 >  
template<typaname T>
void bubble_sort(T nums[], int len) {
    int len = nums.size();
    for (int i = 0; i < len - 1; ++i)
        for (int j = 0; j < len - 1 - i; ++j)
            if (nums[j] > nums[j + 1])
                swap(nums[j], nums[j + 1]);
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="selection-sort"></a>

### SelectionSort
```cpp
/*
(有序区, 无序区) 在无序区里找一个最小的元素跟在有序区的后面。对数组：比较得多，换得少
*/
void SelectionSort(vector<int> &nums) {
    int minIdx, len = nums.size();
    for (int i = 0; i < len - 1; ++i) {
        minIdx = i;
        // 找到最小的
        for (int j = i + 1; j < len; ++j) {
            if (nums[j] < nums[minIdx]) {
                minIdx = j;
            }
        }
        if (i != minIdx)
            swap(nums[i], nums[minIdx]);
    }
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="insert-sort"></a>

### InsertSort
```cpp
/*
(有序区, 无序区) 把无序区的第一个元素插入到有序区的合适的位置。对数组：比较得少，换得多
*/
void InsertSort(vector<int> &nums) {
    int len = nums.size();
    for (int i = 1; i < len; ++i) {
        auto temp = nums[i];
        for (int j = i - 1; j >= 0; --j) {
            if (nums[j] > temp) {
                nums[j + 1] = nums[j];
                nums[j] = temp;
            }
            else
                break;
        }
    }
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="quick-sort"></a>

### QuickSort
```cpp
/*
(小数, 基准元素, 大数)
在区间中随机挑选一个元素作基准，将小于基准的元素放在基准之前，大于基准的元素放在基准之后，再分别对小数区与大数区进行排序
*/
void QuickSort(vector<int> &nums, int low, int high) {
    if (low >= high)
        return;
    int first = low;
    int last = high;
    int key = nums[first];
    while (first < last) {
        // 先从右边开始，找到小于的
        while (first < last && nums[last] >= key)
            last--;
        while (first < last && nums[first] <= key)
            first++;
        if (first < last)
            swap(nums[first], nums[last]);
    }
    // 基准置位
    if (nums[first] < nums[low])
        swap(nums[low], nums[first]);
    else
        first++;
    QuickSort(nums, low, first - 1);
    QuickSort(nums, first + 1, high);
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="heap-sort"></a>

### HeapSort
```cpp
/*
(大顶堆, 有序区) 交换堆顶元素和大顶堆末尾元素，恢复大顶堆
*/
void max_heapify(int nums[], int start, int end) {
    int fIdx = start;
    int cIdx = fIdx * 2 + 1;
    while (cIdx <= end) {
        // 选择较大的子节点
        if (cIdx + 1 <= end && nums[cIdx] < nums[cIdx + 1])
            cIdx++;
        
        if (nums[fIdx] > nums[cIdx])
            return;
        // 交换父子节点，向下调整
        else {
            swap(nums[fIdx], nums[cIdx]);
            fIdx = cIdx;
            cIdx = fIdx * 2 + 1;
        }
    }
}

void heap_sort(int nums[], int len) {
    // 构造大顶堆
    for (int i = len - 1; i >= 0; --i) 
        max_heapify(nums, i, len - 1);
    // 将堆顶元素与最后元素 (有序元素的前一位) 交换
    // 调整大顶堆 (有序元素前)
    for (int i = len - 1; i > 0; --i) {
        swap(nums[0], nums[i]);
        max_heapify(nums, 0, i - 1);
    }
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="merge-sort"></a>

### MergeSort
```cpp
/**/

// 递归版本
template<typename T> 
void merge_sort_recursive(T arr[], T reg[], int start, int end) {
    if (start >= end)   return;
    int len = end - start, mid = (len >> 2) + start;
    int start1 = start, end1 = mid;
    int start2 = mid + 1, end2 = end;
    merge_sort_recursive(arr, reg, start1, end1);
    merge_sort_recursive(arr, reg, start2, end2);
    int k = start;
    while (start1 <= end1 && start2 <= end2)
        reg[k++] = arr[start1] < arr[start2] ? arr[start1++] : arr[start2++];

    while (start1 <= end1)
        reg[k++] = arr[start1++];
    while (start2 <= end2)
        reg[k++] = arr[start2++];
    for (k = start; k <= end; ++k) 
        arr[k] = reg[k];
}

template<typename T> 
void merge_sort(T arr[], const int& len) {
    // 辅助数组
    T * reg = new T[len];
    merge_sort_recursive(arr, reg, 0, len - 1);
    delete[] reg;
}

// 非递归版本
template<typename T>
void merge_sort(T arr[], const int& len) {
    T* a = arr;
    T* b = new T[len];
    for (int seg = 1; seg < len; seg += seg) {
        for (int start = 0; start < len; start += seg + seg) {
            int low = start;
            int mid = min(start + seg, len);
            int high = min(start + seg + seg, len);
            int k = low;
            int start1 = low, end1 = mid;
            int start2 = mid, end2 = high;
            while (start1 < end1 && start2 < end2)
                b[k++] = a[start1] < a[start2] ? a[start1++] : a[start2++];
            while (start1 < end1)
                b[k++] = a[start1++];
            while (start2 < end2)
                b[k++] = a[start2++];
        }
        swap(a, b);
    }
    // 在归并的过程中， a、b 值 (数组首地址值) 一直在发生交换
    // 如果排序过程结束后，a 指向的是原来 b 数组首地址
    // 1、排序结果始终在 a 数组
    // 2、此时 arr 还没更新 (b 与 arr 指向相同地址)
    // 故需要把 a 数组内容复制到 arr 数组；让 b 指向它初始的地址，以便释放
    if (a != arr) {
        for (int i = 0; i < len; i++)
            b[i] = a[i];
        b = a;
    }
    
    delete[] b;
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="shell-sort"></a>

### ShellSort
```cpp
/*
每一轮按照事先决定的间隔进行插入排序，间隔会依次缩小，最后一次一定要是 1
*/
template<typename T>
void shell_sort(T arr[], int length) {
    int gap = 1;
    // 选择一个 gap 值
    while (gap < length / 3)
        gap = 3 * gap + 1;
    while (gap >= 1) {
        for (int i = gap; i < length: ++i) {
            for (int j = i; j >= gap && arr[j] < arr[j - gap]; j -= gap) {
                swap(arr[j], arr[j - gap]);
            }
        }
        gap = gap / 3;
    }
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="count-sort"></a>

### CountSort
```cpp
/*
计数排序不是基于元素比较，而是利用数组下标来确定元素的正确位置
计数排序可以看作是一种桶排序

计数排序基于一个假设，待排序数列的所有数均为整数，且出现在(0, k) 的区间之内
如果 k (待排数组的最大值) 过大则会引起较大的空间复杂度，一般是用来排序 0 到 100 之间的数字的最好的算法
时间复杂度为 O(n+k) ，空间复杂度为 O(n+k)
*/
void CountSort(vector<int>& vecRaw, vector<int>& vecObj) {
    if (vecRaw.size() == 0) return;
    int len = *max_element(vecRaw.begin(), vecRaw.end()) + 1;
    vector<int> vecCount(len, 0);

    // 统计 value 的次数
    for (int i = 0; i < vecRaw.size(); ++i)
        vecCount[vecRaw[i]]++;
    // 次数类和，方便逆序更新
    for (int i = 1; i < len; ++i)
        vecCount[i] += vecCount[i - 1];
    // 逆序保证排序的稳定性
    for (int i = vecRaw.size() - 1; i >= 0; --i) 
        vecObj[--vecCount[vecRaw[i]]] = vecRaw[i];
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="bucket-sort"></a>

### BucketSort
```cpp
/*
桶排序：将值为 i 的元素放入 f(i) 号桶，最后依次把桶里的元素倒出来。
桶排序思路：
1. 设置一个定量的数组当作空桶
2. 寻访序列，并且把元素放到对应的桶
3. 对每个不是空的桶进行排序
4. 从不是空的桶里把元素再放回原来的序列中。

*/

// 假设数据分布在 [0，100)之间，每个桶内部用链表表示，在数据入桶的同时插入排序，然后把各个桶中的数据合并
// 计数排序可以看作是一种桶排序

const int BUCKET_NUM = 10;

struct ListNode {
    explicit ListNode(int i = 0) : val(i), next(NULL) {}
    int val;
    ListNode* next;
}

ListNode* insert(ListNode* head, int value) {
    ListNode* dummyNode;
    ListNode* newNode = new ListNode(value);
    ListNode *pre, *cur;
    dummyNode->next = head;
    pre = dummyNode;
    cur =  head;
    while (cur && cur->val <= value) {
        pre = cur;
        cur = cur->next;
    }
    newNode->next = cur;
    pre->next = newNode;
    return dummyNode->next;
}

ListNode* merge(ListNode *head1, ListNode *head2) {
    ListNode* dummyNode;
    ListNode* cur = dummyNode;
    while (head1 && head2) {
        if (head1->val <= head2->val) {
            cur->next = head1;
            head1 = head1->next;
        }
        else {
            cur->next = head2;
            head2 = head2->next;
        }
        cur = cur->next;
    }
    if (head1)  cur->next = head1;
    if (head2)  cur->next = head2;
    return dummyNode->next;
}

void BucketSort(int arr[], int len) {
    vector<ListNode*> buckets(BUCKET_NUM, (ListNode*)(0));
    for (int i = 0; i < n; ++i) {
        int index = arr[i] / BUCKET_NUM;
        ListNode *head = buckets[index];
        buckets[index] = insert(head, arr[i]);
    }
    ListNode *head = buckets[0];
    for (int i = 1; i < BUCKET_NUM; ++i)
        head = merge(head, buckets[i]);
    for (int i = 0; i < n; ++i) {
        arr[i] = head->val;
        head = head->next;
    }
}
```

<div align="right"><a href="#sort-algorithm">↩️</a></div>
<a id="radix-sort"></a>

### RadixSort
```cpp
/*
基数排序 (Radix Sort) 是桶排序的扩展
基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较

具体做法是：将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。
然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列
*/

// 最大数的位数
int getMaxNumLen(int arr[], int len) {
    int maxVal = arr[0];
    for (int i = 1; i < len; ++i)
        if (arr[i] > maxVal)
            maxVal = arr[i];
    int maxNumLen = 1;
    int p = 10;
    while (maxVal >= p) {
        // 使用除法避免溢出
        maxVal /= 10;
        ++maxNumLen;
    }
    return maxNumLen;
}

// 按某位进行排序
void countSort(int arr[], int len, int exp) {
    // exp = 1, 2, 3... 对应个、十、百位...
    int *output = new int[len];
    int buckets[10] = { 0 };
    int radix = 1;
    while (--exp)
        radix *= 10;
    int i;
    // 记录某位上数出现的次数
    for (i = 0; i < len; ++i)
        buckets[(arr[i] / radix) % 10]++;
    // 便于逆序更新
    for (i = 1; i < 10; ++i)
        buckets[i] += buckets[i - 1];
    // 将数据存储到临时数组
    for (i = len - 1; i >= 0; --i) {
        int num = (arr[i] / radix) % 10;
        output[buckets[num] - 1] = arr[i];
        buckets[num]--;
    }
    // 更新 arr
    for (i = 0; i < len; ++i)
        arr[i] = output[i];
    delete[] output;
}

void radixSort(int arr[], int len) {
    int maxNumLen = getMaxNumLen(arr, len);
    // 从个位开始排序
    for (int exp = 1; exp <= maxNumLen; ++exp) {
        countSort(arr, len, exp);
    }
}
```
<div align="right"><a href="#sort-algorithm">↩️</a></div>

<a id="smart-pointer"></a>

## 智能指针



### shared_ptr

```cpp
template<typename T>
class Shared_ptr {
private:
    size_t* m_count;
    T* m_ptr;
public:
    // 构造函数
    Shared_ptr() : m_ptr(nullptr), m_count(new size_t) {}
    Shared_ptr(T* ptr) : m_ptr(ptr), m_count(new size_t) { *m_count = 1; }
    // 析构函数
    ~Shared_ptr() {
        --(*m_count);
        if (*m_count == 0) {
            delete m_ptr;
            delete m_count;
            m_ptr = nullptr;
            m_count = nullptr;
        }
    }
    // 拷贝构造
    Shared_ptr(const Shared_ptr &ptr) : m_count(ptr.m_count), m_ptr(ptr.m_ptr) { ++(*m_count); }
    // 拷贝赋值运算符
    void operator = (const Shared_ptr &ptr) { Shared_ptr(std::move(ptr)); }
    // 移动构造函数
    Shared_ptr(const Shared_ptr &&ptr) : m_count(ptr.m_count), m_ptr(ptr.m_ptr) { ++(*m_count); }
    // 移动赋值运算符
    void operator = (const Shared_ptr &&ptr) { Shared_ptr(std::move(ptr)); }
    // 解引用运算符
    T& operator * () { return *m_ptr; }
    // 解头运算符
    T* operator -> () { return m_ptr; }
    // 重载 bool 值操作
    operator bool() { return m_ptr == nullptr; }
    
    T* get() { return m_ptr; }
    size_t use_count() { return *m_count; }
    bool unique() { return *m_count == 1; }
    void swap(Shared_ptr &ptr) { std::swap(*this, ptr); }
};
```



<div align="right"><a href="#content">⏫</a></div>